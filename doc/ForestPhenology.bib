Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Brieger2019a,
abstract = {Forest structure is a crucial component in the assessment of whether a forest is likely to act as a carbon sink under changing climate. Detailed 3D structural information about the tundra-taiga ecotone of Siberia is mostly missing and still underrepresented in current research due to the remoteness and restricted accessibility. Field based, high-resolution remote sensing can provide important knowledge for the understanding of vegetation properties and dynamics. In this study, we test the applicability of consumer-grade Unmanned Aerial Vehicles (UAVs) for rapid calculation of stand metrics in treeline forests. We reconstructed high-resolution photogrammetric point clouds and derived canopy height models for 10 study sites from NE Chukotka and SW Yakutia. Subsequently, we detected individual tree tops using a variable-window size local maximum filter and applied a marker-controlled watershed segmentation for the delineation of tree crowns.With this, we successfully detected 67.1{\%} of the validation individuals. Simple linear regressions of observed and detected metrics show a better correlation (R2) and lower relative root mean square percentage error (RMSE{\%}) for tree heights (mean R2 = 0.77, mean RMSE{\%} = 18.46{\%}) than for crown diameters (mean R2 = 0.46, mean RMSE{\%} = 24.9{\%}). The comparison between detected and observed tree height distributions revealed that our tree detection method was unable to representatively identify trees {\textless}2 m. Our results show that plot sizes for vegetation surveys in the tundra-taiga ecotone should be adapted to the forest structure and have a radius of {\textgreater}15-20 m to capture homogeneous and representative forest stands. Additionally, we identify sources of omission and commission errors and give recommendations for their mitigation. In summary, the efficiency of the used method depends on the complexity of the forest's stand structure.},
author = {Brieger, Frederic and Herzschuh, Ulrike and Pestryakova, Luidmila A. and Bookhagen, Bodo and Zakharov, Evgenii S. and Kruse, Stefan},
doi = {10.3390/rs11121447},
file = {:home/marus200/Documents/library/Brieger et al/Brieger et al. - 2019 - Advances in the Derivation of Northeast Siberian Forest Metrics Using High-Resolution UAV-Based Photogrammetric.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Forest structure,Photogrammetry,Point cloud,Remote sensing,Structure from motion,Tundra-taiga ecotone,UAV},
month = {jun},
number = {12},
pages = {1447},
title = {{Advances in the derivation of Northeast Siberian forest metrics using high-resolution UAV-based photogrammetric point clouds}},
url = {https://www.mdpi.com/2072-4292/11/12/1447},
volume = {11},
year = {2019}
}
@article{Rodrigues2012a,
abstract = {PhenoSat is an experimental software tool that extracts phenological information from satellite vegetation index time-series. Temporal satellite NDVI data provided by VEGETATION sensor from three different vegetation types (Vineyard, Closed Deciduous Forest and Deciduous Shrubland with Sparse Trees) and for different geographical locations were used to test the ability of the software in extracting vegetation dynamics information. Six noise reduction filters were tested: piecewise-logistic, Savitzky-Golay, cubic smoothing splines, Gaussian models, Fourier series and polynomial curve fitting. The results showed that PhenoSat is an useful tool to extract phenological NDVI metrics, providing similar results to those obtained from field measurements. The best results presented correlations of 0.89 (n=6; p {\&} {\#}60;0.01) and 0.71 (n=6; p {\&} {\#}60;0.06) for the green-up and maximum stages, respectively. In the fitting process, the polynomial and Gaussian algorithms over smoothed the peak related with a double-growth season, the opposite to the other methods that could detect more accurately this peak. {\textcopyright} 2012 IEEE.},
author = {Rodrigues, Arlete and Marcal, Andre R.S. and Cunha, M{\'{a}}rio},
doi = {10.1109/IGARSS.2012.6352507},
isbn = {9781467311595},
journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
keywords = {NDVI,PhenoSat,Phenology,SPOT VGT,Time-series},
number = {May 2014},
pages = {4926--4929},
title = {{Phenology parameter extraction from time-series of satellite vegetation index data using phenosat}},
year = {2012}
}
@article{Ulsig2017a,
abstract = {{\textcopyright} 2017 by the authors; licensee MDPI, Basel, Switzerland. Long-term observations of vegetation phenology can be used to monitor the response of terrestrial ecosystems to climate change. Satellite remote sensing provides the most efficient means to observe phenological events through time series analysis of vegetation indices such as the Normalized Difference Vegetation Index (NDVI). This study investigates the potential of a Photochemical Reflectance Index (PRI), which has been linked to vegetation light use efficiency, to improve the accuracy of MODIS-based estimates of phenology in an evergreen conifer forest. Timings of the start and end of the growing season (SGS and EGS) were derived from a 13-year-long time series of PRI and NDVI based on a MAIAC (multi-angle implementation of atmospheric correction) processed MODIS dataset and standard MODIS NDVI product data. The derived dates were validated with phenology estimates from ground-based flux tower measurements of ecosystem productivity. Significant correlations were found between the MAIAC time series and ground-estimated SGS (R2= 0.36-0.8), which is remarkable since previous studies have found it difficult to observe inter-annual phenological variations in evergreen vegetation from satellite data. The considerably noisier NDVI product could not accurately predict SGS, and EGS could not be derived successfully from any of the time series. While the strongest relationship overall was found between SGS derived from the ground data and PRI, MAIAC NDVI exhibited high correlations with SGS more consistently (R2{\textgreater} 0.6 in all cases). The results suggest that PRI can serve as an effective indicator of spring seasonal transitions, however, additional work is necessary to confirm the relationships observed and to further explore the usefulness of MODIS PRI for detecting phenology.},
author = {Ulsig, Laura and Nichol, Caroline J. and Huemmrich, Karl F. and Landis, David R. and Middleton, Elizabeth M. and Lyapustin, Alexei I. and Mammarella, Ivan and Levula, Janne and Porcar-Castell, Albert},
doi = {10.3390/rs9010049},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Ecosystem productivity,MODIS,Normalized difference vegetation index (NDVI),Phenology,Photochemical reflectance index (PRI),Time series analysis},
number = {1},
title = {{Detecting inter-annual variations in the phenology of evergreen conifers using long-term MODIS vegetation index time series}},
volume = {9},
year = {2017}
}
@article{Hird2017,
abstract = {Photogrammetric point clouds (PPCs) provide a source of three-dimensional (3-D) remote sensing data that is well-suited to use over small areas that are within the scope of observation by unmanned aerial vehicles (UAVs). We compared PPC-based structural metrics to traditional ground surveys conducted by field personnel in order to assess the capacity of PPC data to contribute to vegetation-reclamation surveys. We found good statistical agreement between key structural vegetation parameters, such as mean and maximum vegetation height, with PPC metrics successfully predicting most height and tree-diameter metrics using multivariate linear regression. However, PPC metrics were not as useful for estimating ground-measured vegetation cover. We believe that part of the issue lies in the mismatch between PPC- and ground-based measurement approaches, including subjective judgement on behalf of ground crews: a topic that requires more investigation. Our work highlights the emerging value of UAV-based PPCs to complement, and in some cases supplement, traditional ground-based sources of measured vegetation structure.},
author = {Hird, Jennifer N. and Montaghi, Alessandro and McDermid, Gregory J. and Kariyeva, Jahan and Moorman, Brian J. and Nielsen, Scott E. and McIntosh, Anne C.S.},
doi = {10.3390/rs9050413},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Ecological recovery,Photogrammetry,Point clouds,Reclamation,Unmanned aerial vehicles,Vegetation cover,Vegetation height,Vegetation structure},
number = {5},
title = {{Use of unmanned aerial vehicles for monitoring recovery of forest vegetation on petroleum well sites}},
volume = {9},
year = {2017}
}
@article{Larrinaga2019,
abstract = {During recent years unmanned aerial vehicles (UAVs) have been increasingly used for research and application in both agriculture and forestry. Nevertheless, most of this work has been devoted to improving accuracy and explanatory power, often at the cost of usability and affordability. We tested a low-cost UAV and a simple workflow to apply four different greenness indices to the monitoring of pine (Pinus sylvestris and P. nigra) post-fire regeneration in a Mediterranean forest. We selected two sites and measured all pines within a pre-selected plot. Winter flights were carried out at each of the sites, at two flight heights (50 and 120 m). Automatically normalized images entered an structure from motion (SfM) based photogrammetric software for restitution, and the obtained point cloud and orthomosaic processed to get a canopy height model and four different greenness indices. The sum of pine diameter at breast height (DBH) was regressed on summary statistics of greenness indices and the canopy height model. Excess green index (ExGI) and green chromatic coordinate (GCC) index outperformed the visible atmospherically resistant index (VARI) and green red vegetation index (GRVI) in estimating pine DBH, while canopy height slightly improved the models. Flight height did not severely affect model performance. Our results show that low cost UAVs may improve forest monitoring after disturbance, even in those habitats and situations where resource limitation is an issue.},
author = {Larrinaga, Asier R. and Brotons, Lluis},
doi = {10.3390/drones3010006},
journal = {Drones},
keywords = {flight,forest regeneration,greenness index,low-cost uav,pinus nigra,pinus sylvestris},
number = {1},
pages = {6},
title = {{Greenness Indices from a Low-Cost UAV Imagery as Tools for Monitoring Post-Fire Forest Recovery}},
volume = {3},
year = {2019}
}
@article{Prabakaran2013,
abstract = {Uttara Kannada district has diverse forest types ranging from tropical evergreen to dry deciduous. This study used remote sensing-based NDVI time-series data from 1999 to 2007 to create the phenological curves and maps for every season and each phenological parameter was created using TIMESAT program. It was observed that evergreen forest sites are always followed by deciduous forest sites in all phenological events. The season starts by August and ends by June the following year in evergreen forests. In deciduous forests, the season starts by May and ends by March the following year. Evergreen forests have longer season than deciduous forests. Maximum temperature and rainfall have negative (r = -0.785) and positive (r = 0.502) correlation respectively with start of the season. However, maximum temperature has high positive correlation (r = 0.942) with leaf senescence. This article indicates that more studies on the phenology of natural vegetation will help to understand the responses of plants towards the changes in the climatic condition.},
author = {Prabakaran, C. and Singh, C. P. and Panigrahy, S. and Parihar, J. S.},
issn = {00113891},
journal = {Current Science},
keywords = {Climatic factors,Forest phenology,Remote sensing,Time-series data},
number = {6},
pages = {795--802},
title = {{Retrieval of forest phenological parameters from remote sensing-based NDVI time-series data}},
volume = {105},
year = {2013}
}
@article{Ide2010,
abstract = {Vegetation phenology such as the onset of green-up and senescence is strongly controlled by climate and other environmental factors, and in turn affects the terrestrial carbon balance. Therefore, phenological observation is important as an indicator of global warming and for estimation of the terrestrial carbon balance. Because phenological responses differ from species to species, precise monitoring from the species scale to the global scale is required. In this study, we analyzed images from digital cameras, which have proliferated in recent years, to investigate their utility as remote sensors. We collected daily images taken by digital cameras in national parks across Japan over 8. years in wetland mixed deciduous forest, and evergreen broadleaved forest. Values of red, green, and blue (RGB) channels in each pixel within images were extracted, and a vegetation green excess index (2G-RBi) was calculated to detect phenology. The time series of 2G-RBi showed clear phenological patterns of each vegetation type in each year at the species or community scale. Even physiological damage due to a typhoon was detected. The dates of green-up were estimated easily and objectively from the second derivative of 2G-RBi, and a trend in yearly green-up dates of various types of vegetation was demonstrated. Furthermore, a strong correlation between interannual variations in green-up dates and local spring temperature was found, and the sensitivity of green-up date to temperature was revealed. The results suggest the utility of digital cameras for phenological observations at precise temporal and spatial resolutions, despite a year-to-year drift of color balance of camera as a technical device. As a form of near-surface remote sensing, digital cameras could obtain significant ecological information. Establishing camera networks could help us understand phenological responses at a wide range of scales. {\textcopyright} 2010 Elsevier B.V.},
author = {Ide, Reiko and Oguma, Hiroyuki},
doi = {10.1016/j.ecoinf.2010.07.002},
issn = {15749541},
journal = {Ecological Informatics},
keywords = {Digital camera,Green excess index,Green-up date,Japan,RGB,Temperature sensitivity,Vegetation phenology},
month = {sep},
number = {5},
pages = {339--347},
publisher = {Elsevier},
title = {{Use of digital cameras for phenological observations}},
url = {https://www.sciencedirect.com/science/article/pii/S1574954110000762},
volume = {5},
year = {2010}
}
@article{Krause2019a,
abstract = {The measurement of tree height has long been an important tree attribute for the purpose of calculating tree growth, volume, and biomass, which in turn deliver important ecological and economical information to decision makers. Tree height has traditionally been measured by indirect field-based techniques, however these methods are rarely contested. With recent advances in Unmanned Aerial Vehicle (UAV) remote sensing technologies, the possibility to acquire accurate tree heights semi-automatically has become a reality. In this study, photogrammetric and field-based tree height measurements of a Scots Pine stand were validated using destructive methods. The intensive forest monitoring site implemented for the study was configured with permanent ground control points (GCPs) measured with a Total Station (TS). Field-based tree height measurements resulted in a similar level of error to that of the photogrammetric measurements, with root mean square error (RMSE) values of 0.304 m (1.82{\%}) and 0.34 m (2.07{\%}), respectively (n = 34). A conflicting bias was, however, discovered where field measurements tended to overestimate tree heights and photogrammetric measurements were underestimated. The photogrammetric tree height measurements of all trees (n = 285) were validated against the field-based measurements and resulted in a RMSE of 0.479 m (2.78{\%}). Additionally, two separate photogrammetric tree height datasets were compared (n = 251), and a very low amount of error was observed with a RMSE of 0.138 m (0.79{\%}), suggesting a high potential for repeatability. This study shows that UAV photogrammetric tree height measurements are a viable option for intensive forest monitoring plots and that the possibility to acquire within-season tree growth measurements merits further study. Additionally, it was shown that negative and positive biases evident in field-based and UAV-based photogrammetric tree height measurements could potentially lead to misinterpretation of results when field-based measurements are used as validation.},
author = {Krause, Stuart and Sanders, Tanja G.M. and Mund, Jan Peter and Greve, Klaus},
doi = {10.3390/rs11070758},
file = {:home/marus200/Documents/library/Krause et al/Krause et al. - 2019 - UAV-Based Photogrammetric Tree Height Measurement for Intensive Forest Monitoring.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Intensive forest monitoring,Photogrammetry,Precision forestry,Tree height,UAV},
month = {mar},
number = {7},
pages = {758},
publisher = {MDPI AG},
title = {{UAV-based photogrammetric tree height measurement for intensive forest monitoring}},
volume = {11},
year = {2019}
}
@article{Marques2019a,
abstract = {Unmanned aerial vehicles have become a popular remote sensing platform for agricultural applications, with an emphasis on crop monitoring. Although there are several methods to detect vegetation through aerial imagery, these remain dependent of manual extraction of vegetation parameters. This article presents an automatic method that allows for individual tree detection and multi-temporal analysis, which is crucial in the detection of missing and new trees and monitoring their health conditions over time. The proposed method is based on the computation of vegetation indices (VIs), while using visible (RGB) and near-infrared (NIR) domain combination bands combined with the canopy height model. An overall segmentation accuracy above 95{\%} was reached, even when RGB-based VIs were used. The proposed method is divided in three major steps: (1) segmentation and first clustering; (2) cluster isolation; and (3) feature extraction. This approach was applied to several chestnut plantations and some parameters-such as the number of trees present in a plantation (accuracy above 97{\%}), the canopy coverage (93{\%} to 99{\%} accuracy), the tree height (RMSE of 0.33 m and R2 = 0.86), and the crown diameter (RMSE of 0.44 m and R2 = 0.96)-were automatically extracted. Therefore, by enabling the substitution of time-consuming and costly field campaigns, the proposed method represents a good contribution in managing chestnut plantations in a quicker and more sustainable way.},
author = {Marques, Pedro and P{\'{a}}dua, Lu{\'{i}}s and Ad{\~{a}}o, Telmo and Hru{\v{s}}ka, Jon{\'{a}}{\v{s}} and Peres, Emanuel and Sousa, Ant{\'{o}}nio and Sousa, Joaquim J.},
doi = {10.3390/RS11070855},
file = {:home/marus200/Documents/library/Marques et al/Marques et al. - 2019 - UAV-Based Automatic Detection and Monitoring of Chestnut Trees.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Automatic plantation monitoring,Chestnut trees,Image processing,Multi-temporal analysis,Photogrammetric processing,Remote sensing,Unmanned aerial vehicles},
month = {apr},
number = {7},
pages = {855},
publisher = {MDPI AG},
title = {{UAV-based automatic detection and monitoring of chestnut trees}},
url = {https://link.springer.com/book/10.1007/978-3-540-32572-7},
volume = {11},
year = {2019}
}
@article{Elatawneh2013,
author = {Elatawneh, A and Rappl, A and Rehush, N and Schneider, T and Knoke, T},
journal = {5. RESA Workshop 4/2013},
number = {May 2014},
pages = {1--10},
title = {{Forest tree species communities identification using multi phenological stages RapidEye data : case study in the forest of Freising}},
year = {2013}
}
@article{Nevalainen2017,
abstract = {{\textcopyright} 2017 by the authors. Small unmanned aerial vehicle (UAV) based remote sensing is a rapidly evolving technology. Novel sensors and methods are entering the market, offering completely new possibilities to carry out remote sensing tasks. Three-dimensional (3D) hyperspectral remote sensing is a novel and powerful technology that has recently become available to small UAVs. This study investigated the performance of UAV-based photogrammetry and hyperspectral imaging in individual tree detection and tree species classification in boreal forests. Eleven test sites with 4151 reference trees representing various tree species and developmental stages were collected in June 2014 using a UAV remote sensing system equipped with a frame format hyperspectral camera and an RGB camera in highly variable weather conditions. Dense point clouds were measured photogrammetrically by automatic image matching using high resolution RGB images with a 5 cm point interval. Spectral features were obtained from the hyperspectral image blocks, the large radiometric variation of which was compensated for by using a novel approach based on radiometric block adjustment with the support of in-flight irradiance observations. Spectral and 3D point cloud features were used in the classification experiment with various classifiers. The best results were obtained with Random Forest and Multilayer Perceptron (MLP) which both gave 95{\%} overall accuracies and an F-score of 0.93. Accuracy of individual tree identification from the photogrammetric point clouds varied between 40{\%} and 95{\%}, depending on the characteristics of the area. Challenges in reference measurements might also have reduced these numbers. Results were promising, indicating that hyperspectral 3D remote sensing was operational from a UAV platform even in very difficult conditions. These novel methods are expected to provide a powerful tool for automating various environmental close-range remote sensing tasks in the very near future.},
author = {Nevalainen, Olli and Honkavaara, Eija and Tuominen, Sakari and Viljanen, Niko and Hakala, Teemu and Yu, Xiaowei and Hyypp{\"{a}}, Juha and Saari, Heikki and P{\"{o}}l{\"{o}}nen, Ilkka and Imai, Nilton N. and Tommaselli, Antonio M.G.},
doi = {10.3390/rs9030185},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Classification,Forest,Hyperspectral,Photogrammetry,Point cloud,Radiometry,UAV},
number = {3},
title = {{Individual tree detection and classification with UAV-Based photogrammetric point clouds and hyperspectral imaging}},
volume = {9},
year = {2017}
}
@article{Zhang2003,
abstract = {Accurate measurements of regional to global scale vegetation dynamics (phenology) are required to improve models and understanding of inter-annual variability in terrestrial ecosystem carbon exchange and climate-biosphere interactions. Since the mid-1980s, satellite data have been used to study these processes. In this paper, a new methodology to monitor global vegetation phenology from time series of satellite data is presented. The method uses series of piecewise logistic functions, which are fit to remotely sensed vegetation index (VI) data, to represent intra-annual vegetation dynamics. Using this approach, transition dates for vegetation activity within annual time series of VI data can be determined from satellite data. The method allows vegetation dynamics to be monitored at large scales in a fashion that it is ecologically meaningful and does not require pre-smoothing of data or the use of user-defined thresholds. Preliminary results based on an annual time series of Moderate Resolution Imaging Spectroradiometer (MODIS) data for the northeastern United States demonstrate that the method is able to monitor vegetation phenology with good success. {\textcopyright} 2002 Elsevier Science Inc. All rights reserved.},
author = {Zhang, Xiaoyang and Friedl, Mark A. and Schaaf, Crystal B. and Strahler, Alan H. and Hodges, John C.F. and Gao, Feng and Reed, Bradley C. and Huete, Alfredo},
doi = {10.1016/S0034-4257(02)00135-9},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {MODIS,Remote sensing,Vegetation phenology},
month = {mar},
number = {3},
pages = {471--475},
publisher = {Elsevier},
title = {{Monitoring vegetation phenology using MODIS}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0034425702001359},
volume = {84},
year = {2003}
}
@article{Richardson2018,
abstract = {Tracking vegetation phenology across diverse North American biomes using PhenoCam imagery},
author = {Richardson, Andrew D. and Hufkens, Koen and Milliman, Tom and Aubrecht, Donald M. and Chen, Min and Gray, Josh M. and Johnston, Miriam R. and Keenan, Trevor F. and Klosterman, Stephen T. and Kosmala, Margaret and Melaas, Eli K. and Friedl, Mark A. and Frolking, Steve},
doi = {10.1038/sdata.2018.28},
issn = {20524463},
journal = {Scientific Data},
pages = {1--24},
title = {{Tracking vegetation phenology across diverse North American biomes using PhenoCam imagery}},
volume = {5},
year = {2018}
}
@article{Fraser2018a,
abstract = {Unmanned Aerial Systems (UAS) offer users the ability to capture large amounts of imagery at unprecedented spatial resolutions due to their flexible designs, low costs, automated workflows, and minimal technical knowledge barriers. Their rapid extension into new disciplines promotes the necessity to question and understand the implications of data capture and processing parameter decisions on the respective output completeness. This research provides a culmination of quantitative insight using an eBee Plus, fixed-wing UAS for collecting robust data on complex forest environments. These analyses differentiate from measures of accuracy, which were derived from positional comparison to other data sources, to instead guide applications of comprehensive coverage. Our results demonstrated the impacts of flying height on Structure from motion (SfM) processing completeness, discrepancies in outputs based on software package choice, and the effects caused by processing parameter settings. For flying heights of 50 m, 100 m, and 120 m above the forest canopy, key quality indicators within the software demonstrated the superior performance of the 100-m flying height. These indicators included, among others, image alignment success, the average number of tie points per image, and planimetric model ground sampling distance. We also compared the output results of two leading SfM software packages: Agisoft PhotoScan and Pix4D mapper Pro. Agisoft PhotoScan maintained an 11.8{\%} greater image alignment success and a 9.91{\%} finer planimetric model resolution. Lastly, we compared the "high" and "medium" resolution processing workflows in Agisoft PhotoScan. The high-resolution processing setting achieved a 371{\%} increase in point cloud density, with a 3.1{\%} coarser planimetric model resolution, over a considerably longer processing time. As UAS continue to expand their sphere of influence and develop technologically, best-use practices based on aerial photogrammetry principles must remain apparent to achieve optimal results.},
author = {Fraser, Benjamin T. and Congalton, Russell G.},
doi = {10.3390/rs10060908},
file = {:home/marus200/Documents/library/Fraser, Congalton/Fraser, Congalton - 2018 - Issues in Unmanned Aerial Systems (UAS) data collection of complex forest environments.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Drone,Flight planning,Photogrammetry,Structure from motion (SfM),Unmanned Aerial Systems (UAS),Unmanned Aerial Vehicle (UAV)},
month = {jun},
number = {6},
publisher = {MDPI AG},
title = {{Issues in Unmanned Aerial Systems (UAS) data collection of complex forest environments}},
volume = {10},
year = {2018}
}
@article{Sadeghi2018,
author = {Sadeghi, Sima and Sohrabi, Hormoz},
journal = {Small Unmanned Aerial Systems for Environmental Rwesearch},
number = {6},
pages = {1--5},
title = {{Tree species discrimination using RGB vegetation indices derived from UAV images}},
year = {2018}
}
@article{Wendland1996,
abstract = {An overview of the forestry sector in Costa Rica was undertaken to determine whether the existing management practices of timber resources hold the potential to meet the country's demands for timber in the immediate decades to come, and to identify changes that might be needed in the management of forested lands. To meet these goals, we examined the present status and potential future contribution of the two newest forest sectors: the management of natural forest and plantation forestry. Rcsults indicate that the present management of Costa Rica's timber resources does not hold the potential to meet the country's demands for timber for more than the next ten years without severe loss of its forests. Substantial progress is occurring, but at an insufficient rate. Moreover, despite the considerable headway made in conservation in recent years, the rate of deforestation remains high. A number of factors limit advancement in natural forest management and plantation forestry, both of which have the potential to deaccelerate deforestation. In natural forest management, constraints are the rate at which forests are being brought under management, lack of budgetary provisions for fiscal incentives to private owners who alone cannot be expected to bear the cost of benefits of natural forest management that are national or even global in their distribution, and the weak infrastructure, extension services and research support to meet management goals. In the case of plantation forestry, the capability of this sector to produce commercial timber is not known. Moreover, inadequate management and extension services together with the misuse of the incentive system by private owners is likely to limit the potential of plantations. Institutional constraints include outdated legal and bureaucratic framework, market interventions, absence of clear policy toward natural forest management and plantation forestry, poor investment in infrastructure, extension and research support, and inadequate interaction among various agencies responsible for the development of the forestry sector. Such institutional constraints have allowed the proliferation of disincentives against the development of a sustainable timber sector. If the Costa Rican government's objective is to encourage sustainable forestry, it must first clearly articulate the policy and then create the appropriate legal, economic and institutional framework for implementation of the policy. Costa Rica, with its enlightened public administration system, vast technical and scientific knowledge about its forest ecosystem and extensive assistance from international organizations, must succeed, otherwise prospects for sustainable forestry in thc less fortunate tropical countries would be bleak. {\textcopyright} 1996 by The Haworth Press, Inc. All rights reserved.},
author = {Wendland, Antonio and Bawa, K. S.},
doi = {10.1300/J091v03n02_06},
isbn = {9783540490289},
issn = {1540756X},
journal = {Journal of Sustainable Forestry},
number = {2-3},
pages = {91--156},
title = {{Tropical forestry: The costa rican experience in management of forest resources}},
volume = {3},
year = {1996}
}
@article{Frey2018a,
abstract = {Structural analysis of forests by UAV is currently growing in popularity. Given the reduction in platform costs, and the number of algorithms available to analyze data output, the number of applications has grown rapidly. Forest structures are not only linked to economic value in forestry, but also to biodiversity and vulnerability issues. LiDAR remains the most promising technique for forest structural assessment, but small LiDAR sensors suitable for UAV applications are expensive and are limited to a few manufactures. The estimation of 3D-structures from two-dimensional image sequences called 'Structure from motion' (SfM) overcomes this limitation by photogrammetrically reconstructing point clouds similar to those rendered from LiDAR sensors. The result of these techniques in highly structured terrain strongly depends on the methods employed during image acquisition, therefore structural indices might be vulnerable to misspecifications in flight campaigns. In this paper, we outline how image overlap and ground sampling distances affect image reconstruction completeness in 2D and 3D. Higher image overlaps and coarser GSDs have a clearly positive influence on reconstruction quality. Therefore, higher accuracy requirements in the GSD must be compensated by a higher image overlap. The best results are achieved with an image overlap of {\textgreater} 95{\%} and a resolution of {\textgreater} 5 cm. The most important environmental factors have been found to be wind and terrain elevation, which could be an indicator of vegetation density.},
author = {Frey, Julian and Kovach, Kyle and Stemmler, Simon and Koch, Barbara},
doi = {10.3390/rs10060912},
file = {:home/marus200/Documents/library/Frey et al/Frey et al. - 2018 - UAV photogrammetry of forests as a vulnerable process. A sensitivity analysis for a structure from motion RGB-image.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Forest,Image aggregation,Photogrammetry,Reconstruction quality,Sensitivity analyses,SfM,UAV},
month = {jun},
number = {6},
publisher = {MDPI AG},
title = {{UAV photogrammetry of forests as a vulnerable process. A sensitivity analysis for a structure from motion RGB-image pipeline}},
volume = {10},
year = {2018}
}
@article{Onishi2018a,
abstract = {Automatic classification of trees using remotely sensed data has been a dream of many scientists and land use managers. Recently, Unmanned aerial vehicles (UAV) has been expected to be an easy-to-use, cost-effective tool for remote sensing of forests, and deep learning has attracted attention for its ability concerning machine vision. In this study, using a commercially available UAV and a publicly available package for deep learning, we constructed a machine vision system for the automatic classification of trees. In our method, we segmented a UAV photography image of forest into individual tree crowns and carried out object-based deep learning. As a result, the system was able to classify 7 tree types at 89.0{\%} accuracy. This performance is notable because we only used basic RGB images from a standard UAV. In contrast, most of previous studies used expensive hardware such as multispectral imagers to improve the performance. This result means that our method has the potential to classify individual trees in a cost-effective manner. This can be a usable tool for many forest researchers and managements.},
archivePrefix = {arXiv},
arxivId = {1804.10390},
author = {Onishi, Masanori and Ise, Takeshi},
eprint = {1804.10390},
file = {:home/marus200/Documents/library/Onishi, Ise/Onishi, Ise - 2018 - Automatic classification of trees using a UAV onboard camera and deep learning.pdf:pdf},
month = {apr},
title = {{Automatic classification of trees using a UAV onboard camera and deep learning}},
url = {http://arxiv.org/abs/1804.10390},
year = {2018}
}
@article{Dostalova2018,
author = {Dost{\'{a}}lov{\'{a}}, Alena and Wagner, Wolfgang and Milenkovi{\'{c}}, Milutin and Hollaus, Markus},
doi = {10.1080/01431161.2018.1479788},
journal = {International Journal of Remote Sensing},
number = {21},
pages = {7738--7760},
publisher = {Taylor {\&} Francis},
title = {{Annual seasonality in Sentinel-1 signal for forest mapping and forest type classification}},
url = {https://doi.org/10.1080/01431161.2018.1479788},
volume = {39},
year = {2018}
}
@article{Yan2018a,
abstract = {Forests play a key role in terrestrial ecosystems, and the variables extracted from single trees can be used in various fields and applications for evaluating forest production and assessing forest ecosystem services. In this study, we developed an automated hierarchical single-tree segmentation approach based on the high density three-dimensional (3D) Unmanned Aerial Vehicle (UAV) point clouds. First, this approach obtains normalized non-ground UAV points in data preprocessing; then, a voxel-based mean shift algorithm is used to roughly classify the non-ground UAV points into well-detected and under-segmentation clusters. Moreover, potential tree apices for each under-segmentation cluster are obtained with regard to profile shape curves and finally input to the normalized cut segmentation (NCut) algorithm to segment iteratively the under-segmentation cluster into single trees. We evaluated the proposed method using datasets acquired by a Velodyne 16E LiDAR system mounted on a multi-rotor UAV. The results showed that the proposed method achieves the average correctness, completeness, and overall accuracy of 0.90, 0.88, and 0.89, respectively, in delineating single trees. Comparative analysis demonstrated that our method provided a promising solution to reliable and robust segmentation of single trees from UAV LiDAR data with high point cloud density.},
author = {Yan, Wanqian and Guan, Haiyan and Cao, Lin and Yu, Yongtao and Gao, Sha and Lu, Jian Yong},
doi = {10.3390/rs10121999},
file = {:home/marus200/Documents/library/Yan et al/Yan et al. - 2018 - An Automated Hierarchical Approach for Three-Dimensional Segmentation of Single Trees Using UAV LiDAR Data.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Improved normalized cut,Mean shift,Segmentation,Single tree,UAV LiDAR},
month = {dec},
number = {12},
pages = {1999},
publisher = {MDPI AG},
title = {{An automated hierarchical approach for three-dimensional segmentation of single trees using UAV LiDAR data}},
volume = {10},
year = {2018}
}
@incollection{inbook,
author = {Mountford, G.L. and Atkinson, P.M. and Dash, J. and Lankester, T. and Hubbard, S.},
booktitle = {Sensitivity Analysis in Earth Observation Modelling},
doi = {10.1016/b978-0-12-803011-0.00004-5},
isbn = {9780128030110},
pages = {75--90},
title = {{Sensitivity of Vegetation Phenological Parameters}},
year = {2016}
}
@article{Karkauskaite2017a,
abstract = {{\textcopyright} 2017 by the authors. Satellite remote sensing of plant phenology provides an important indicator of climate change. However, start of the growing season (SOS) estimates in Northern Hemisphere boreal forest areas are known to be challenged by the presence of seasonal snow cover and limited seasonality in the greenness signal for evergreen needleleaf forests, which can both bias and impede trend estimates of SOS. The newly developed Plant Phenology Index (PPI) was specifically designed to overcome both problems. Here we use Moderate Resolution Imaging Spectroradiometer (MODIS) data (2000-2014) to analyze the ability of PPI for estimating start of season (SOS) in boreal regions of the Northern Hemisphere, in comparison to two other widely applied indices for SOS retrieval: the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI). Satellite-based SOS is evaluated against gross primary production (GPP)-retrieved SOS derived from a network of flux tower observations in boreal areas (a total of 81 site-years analyzed). Spatiotemporal relationships between SOS derived from PPI, EVI and NDVI are furthermore studied for different boreal land cover types and regions. The overall correlation between SOS derived from VIs and ground measurements was rather low, but PPI performed significantly better (r = 0.50, p {\textless} 0.01) than EVI and NDVI which both showed a very poor correlation (r = 0.11, p = 0. 16 and r = 0.08, p = 0.24). PPI, EVI and NDVI overall produce similar trends in SOS for the Northern Hemisphere showing an advance in SOS towards earlier dates (0.28, 0.23 and 0.26 days/year), but a pronounced difference in trend estimates between PPI and EVI/NDVI is observed for different land cover types. Deciduous needleleaf forest is characterized by the largest advance in SOS when considering all indices, yet PPI showed less dramatic changes as compared to EVI/NDVI (0.47 days/year as compared to 0.62 and 0.74). PPI SOS trends were found to be higher for deciduous broadleaf forests and savannas (0.54 and 0.56 days/year). Taken together, the findings of this study suggest improved performance of PPI over NDVI and EVI in retrieval of SOS in boreal regions and precautions must be taken when interpreting spatio-temporal patterns of SOS from the latter two indices.},
author = {Karkauskaite, Paulina and Tagesson, Torbern and Fensholt, Rasmus},
doi = {10.3390/rs9050485},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Boreal forest,Climate change,High latitudes,MODIS time series,SOS (start of season),Vegetation phenology},
number = {5},
title = {{Evaluation of the plant phenology index (PPI), NDVI and EVI for start-of-season trend analysis of the Northern Hemisphere boreal zone}},
volume = {9},
year = {2017}
}
@misc{Frison2018,
abstract = {In this study, the potential of Sentinel-1 data to seasonally monitor temperate forests was investigated by analyzing radar signatures observed from plots in the Fontainebleau Forest of the Ile de France region, France, for the period extending from March 2015 to January 2016. Radar backscattering coefficients, $\sigma$0 and the amplitude of temporal interferometric coherence profiles in relation to environmental variables are shown, such as in situ precipitation and air temperature. The high temporal frequency of Sentinel-1 acquisitions (i.e., twelve days, or six, if both Sentinel-1A and B are combined over Europe) and the dual polarization configuration (VV and VH over most land surfaces) made a significant contribution. In particular, the radar backscattering coefficient ratio of VV to VH polarization, $\sigma$V V0/$\sigma$V H0, showed a well-pronounced seasonality that was correlated with vegetation phenology, as confirmed in comparison to NDVI profiles derived from Landsat-8 (r = 0.77) over stands of deciduous trees. These results illustrate the high potential of Sentinel-1 data for monitoring vegetation, and as these data are not sensitive to the atmosphere, the phenology could be estimated with more accuracy than optical data. These observations will be quantitatively analyzed with the use of electromagnetic models in the near future.},
author = {Frison, Pierre Louis and Fruneau, B{\'{e}}n{\'{e}}dicte and Kmiha, Syrine and Soudani, Kamel and Dufr{\^{e}}ne, Eric and {Le Toan}, Thuy and Koleck, Thierry and Villard, Ludovic and Mougin, Eric and Rudant, Jean Paul},
booktitle = {Remote Sensing},
doi = {10.3390/rs10122049},
file = {:home/marus200/Documents/library/Frison et al/Frison et al. - 2018 - Potential of Sentinel-1 data for monitoring temperate mixed forest phenology.pdf:pdf},
issn = {20724292},
keywords = {Interferometric coherence,Radar backscattering coefficient,SAR,Seasonal monitoring,Sentinel-1,Temperate mixed forest},
number = {12},
title = {{Potential of Sentinel-1 data for monitoring temperate mixed forest phenology}},
volume = {10},
year = {2018}
}
@article{Mu2015a,
abstract = {Validation over heterogeneous areas is critical to ensuring the quality of remote sensing products. This paper focuses on the sampling methods used to validate the coarse-resolution fractional vegetation cover (FVC) product in the Heihe River Basin, where the patterns of spatial variations in and between land cover types vary significantly in the different growth stages of vegetation. A sampling method, called the mean of surface with non-homogeneity (MSN) method, and three other sampling methods are examined with real-world data obtained in 2012. A series of 15-m-resolution fractional vegetation cover reference maps were generated using the regressions of field-measured and satellite data. The sampling methods were tested using the 15-m-resolution normalized difference vegetation index (NDVI) and land cover maps over a complete period of vegetation growth. Two scenes were selected to represent the situations in which sampling locations were sparsely and densely distributed. The results show that the FVCs estimated using the MSN method have errors of approximately less than 0.03 in the two selected scenes. The validation accuracy of the sampling methods varies with variations in the stratified non-homogeneity in the different growing stages of the vegetation. The MSN method, which considers both heterogeneity and autocorrelations between strata, is recommended for use in the determination of samplings prior to the design of an experimental campaign. In addition, the slight scaling bias caused by the non-linear relationship between NDVI and FVC samples is discussed. The positive or negative trend of the biases predicted using a Taylor expansion is found to be consistent with that of the real biases.},
author = {Mu, Xihan and Hu, Maogui and Song, Wanjuan and Ruan, Gaiyan and Ge, Yong and Wang, Jinfeng and Huang, Shuai and Yan, Guangjian},
doi = {10.3390/rs71215817},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Fractional vegetation cover,Remote sensing product,Sampling methods,Scaling bias,Spatial autocorrelation,Validation},
number = {12},
pages = {16164--16182},
title = {{Evaluation of sampling methods for validation of remotely sensed fractional vegetation cover}},
volume = {7},
year = {2015}
}
@article{RomeroMartinez2017a,
author = {{Romero Martinez}, Juan Jose and Gao, Yan},
journal = {Asian Conference on Remote Sensing},
number = {October},
title = {{Forest disturbance analysis by phenology of forest covers in Mexico using time series NDVI data}},
year = {2017}
}
@article{Ramezan2019,
abstract = {High spatial resolution (1-5 m) remotely sensed datasets are increasingly being used to map land covers over large geographic areas using supervised machine learning algorithms. Although many studies have compared machine learning classification methods, sample selection methods for acquiring training and validation data for machine learning, and cross-validation techniques for tuning classifier parameters are rarely investigated, particularly on large, high spatial resolution datasets. This work, therefore, examines four sample selection methods-simple random, proportional stratified random, disproportional stratified random, and deliberative sampling-as well as three cross-validation tuning approaches-k-fold, leave-one-out, and Monte Carlo methods. In addition, the effect on the accuracy of localizing sample selections to a small geographic subset of the entire area, an approach that is sometimes used to reduce costs associated with training data collection, is investigated. These methods are investigated in the context of support vector machines (SVM) classification and geographic object-based image analysis (GEOBIA), using high spatial resolution National Agricultural Imagery Program (NAIP) orthoimagery and LIDAR-derived rasters, covering a 2,609 km 2 regional-scale area in northeastern West Virginia, USA. Stratified-statistical-based sampling methods were found to generate the highest classification accuracy. Using a small number of training samples collected from only a subset of the study area provided a similar level of overall accuracy to a sample of equivalent size collected in a dispersed manner across the entire regional-scale dataset. There were minimal differences in accuracy for the different cross-validation tuning methods. The processing time for Monte Carlo and leave-one-out cross-validation were high, especially with large training sets. For this reason, k-fold cross-validation appears to be a good choice. Classifications trained with samples collected deliberately (i.e., not randomly) were less accurate than classifiers trained from statistical-based samples. This may be due to the high positive spatial autocorrelation in the deliberative training set. Thus, if possible, samples for training should be selected randomly; deliberative samples should be avoided.},
author = {Ramezan, Christopher A and Warner, Timothy A and Maxwell, Aaron E},
doi = {10.3390/rs11020185},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Cross-validation,High resolution imagery,Lidar,NAIP,Regional-scale,Training sample selection},
number = {2},
title = {{Evaluation of sampling and cross-validation tuning strategies for regional-scale machine learning classification}},
volume = {11},
year = {2019}
}
@article{Natesan2019,
abstract = {Tree species classification at individual tree level is a challenging problem in forest management. Deep learning, a cutting-edge technology evolved from Artificial Intelligence, was seen to outperform other techniques when it comes to complex problems such as image classification. In this work, we present a novel method to classify forest tree species through high resolution RGB images acquired with a simple consumer grade camera mounted on a UAV platform using Residual Neural Networks. We used UAV RGB images acquired over three years that varied in numerous acquisition parameters such as season, time, illumination and angle to train the neural network. To begin with, we have experimented with limited data towards the identification of two pine species namely red pine and white pine from the rest of the species. We performed two experiments, first with the images from all three acquisition years and the second with images from only one acquisition year. In the first experiment, we obtained 80{\%} classification accuracy when the trained network was tested on a distinct set of images and in the second experiment, we obtained 51{\%} classification accuracy. As a part of this work, a novel dataset of high-resolution labelled tree species is generated that can be used to conduct further studies involving deep neural networks in forestry.},
author = {Natesan, S. and Armenakis, C. and Vepakomma, U.},
doi = {10.5194/isprs-archives-XLII-2-W13-475-2019},
file = {:home/marus200/Documents/library/Natesan, Armenakis, Vepakomma/Natesan, Armenakis, Vepakomma - 2019 - Resnet-based tree species classification using uav images.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {CNN,Classification,Deep Learning Networks,RGB Images,ResNet,Tree Species,UAV},
number = {2/W13},
pages = {475--481},
title = {{Resnet-based tree species classification using uav images}},
volume = {42},
year = {2019}
}
@article{Brockerhoff2017,
abstract = {Forests are critical habitats for biodiversity and they are also essential for the provision of a wide range of ecosystem services that are important to human well-being. There is increasing evidence that biodiversity contributes to forest ecosystem functioning and the provision of ecosystem services. Here we provide a review of forest ecosystem services including biomass production, habitat provisioning services, pollination, seed dispersal, resistance to wind storms, fire regulation and mitigation, pest regulation of native and invading insects, carbon sequestration, and cultural ecosystem services, in relation to forest type, structure and diversity. We also consider relationships between forest biodiversity and multifunctionality, and trade-offs among ecosystem services. We compare the concepts of ecosystem processes, functions and services to clarify their definitions. Our review of published studies indicates a lack of empirical studies that establish quantitative and causal relationships between forest biodiversity and many important ecosystem services. The literature is highly skewed; studies on provisioning of nutrition and energy, and on cultural services, delivered by mixed-species forests are under-represented. Planted forests offer ample opportunity for optimising their composition and diversity because replanting after harvesting is a recurring process. Planting mixed-species forests should be given more consideration as they are likely to provide a wider range of ecosystem services within the forest and for adjacent land uses. This review also serves as the introduction to this special issue of Biodiversity and Conservation on various aspects of forest biodiversity and ecosystem services.},
author = {Brockerhoff, Eckehard G. and Barbaro, Luc and Castagneyrol, Bastien and Forrester, David I. and Gardiner, Barry and Gonz{\'{a}}lez-Olabarria, Jos{\'{e}} Ram{\'{o}}n and Lyver, Phil O.B. and Meurisse, Nicolas and Oxbrough, Anne and Taki, Hisatomo and Thompson, Ian D. and van der Plas, Fons and Jactel, Herv{\'{e}}},
doi = {10.1007/s10531-017-1453-2},
file = {:home/marus200/Documents/library/Brockerhoff et al/Brockerhoff et al. - 2017 - Forest biodiversity, ecosystem functioning and the provision of ecosystem services.pdf:pdf},
issn = {15729710},
journal = {Biodiversity and Conservation},
keywords = {Ecological processes,Mixed-species forest,Planted forest,Tree diversity},
number = {13},
pages = {3005--3035},
title = {{Forest biodiversity, ecosystem functioning and the provision of ecosystem services}},
volume = {26},
year = {2017}
}
@article{Klosterman2018,
abstract = {Forest phenology is a multi-scale phenomenon, arising from processes in leaves and trees, with effects on the ecology of plant communities and landscapes. Because phenology controls carbon and water cycles, which are commonly observed at the ecosystem scale (e.g. eddy flux measurements), it is important to characterize the relation between phenophase transition events at different spatial scales. We use aerial photography recorded from an unmanned aerial vehicle (UAV) to observe plant phenology over a large area (5.4 ha) and across diverse communities, with spatial and temporal resolution at the scale of individual tree crowns and their phenophase transition events (10 m spatial resolution, ∼5 day temporal resolution in spring, weekly in autumn). We validate UAV-derived phenophase transition dates through comparison with direct observations of tree phenology, PhenoCam image analysis, and satellite remote sensing. We then examine the biological correlates of spatial variance in phenology using a detailed species inventory and land cover classification. Our results show that species distribution is the dominant factor in spatial variability of ecosystem phenology. We also explore statistical relations governing the scaling of phenology from an organismic scale (10 m) to forested landscapes (1 km) by analyzing UAV photography alongside Landsat and MODIS data. From this analysis we find that spatial standard deviation in transition dates decreases linearly with the logarithm of increasing pixel size. We also find that fine-scale phenology aggregates to a coarser scale as the median and not the mean date in autumn, indicating coarser scale phenology is less sensitive to the tails of the distribution of sub-pixel transitions in the study area. Our study is the first to observe forest phenology in a spatially comprehensive, whole-ecosystem way, yet with fine enough spatial resolution to describe organism-level correlates and scaling phenomena.},
author = {Klosterman, Stephen and Melaas, Eli and Wang, Jon and Martinez, Arturo and Frederick, Sidni and O'Keefe, John and Orwig, David A. and Wang, Zhuosen and Sun, Qingsong and Schaaf, Crystal and Friedl, Mark and Richardson, Andrew D.},
doi = {10.1016/j.agrformet.2017.10.015},
issn = {01681923},
journal = {Agricultural and Forest Meteorology},
keywords = {Drone,Forest,Phenology,Satellite remote sensing,Spatial scaling,Unmanned aerial vehicle (UAV)},
number = {December 2016},
pages = {397--407},
publisher = {Elsevier},
title = {{Fine-scale perspectives on landscape phenology from unmanned aerial vehicle (UAV) photography}},
url = {http://dx.doi.org/10.1016/j.agrformet.2017.10.015},
volume = {248},
year = {2018}
}
@article{Fricker2019,
abstract = {In this study, we automate tree species classification and mapping using field-based training data, high spatial resolution airborne hyperspectral imagery, and a convolutional neural network classifier (CNN). We tested our methods by identifying seven dominant trees species as well as dead standing trees in a mixed-conifer forest in the Southern Sierra Nevada Mountains, CA (USA) using training, validation, and testing datasets composed of spatially-explicit transects and plots sampled across a single strip of imaging spectroscopy. We also used a three-band ‘Red-Green-Blue' pseudo true-color subset of the hyperspectral imagery strip to test the classification accuracy of a CNN model without the additional non-visible spectral data provided in the hyperspectral imagery. Our classifier is pixel-based rather than object based, although we use three-dimensional structural information from airborne Light Detection and Ranging (LiDAR) to identify trees (points {\textgreater} 5 m above the ground) and the classifier was applied to image pixels that were thus identified as tree crowns. By training a CNN classifier using field data and hyperspectral imagery, we were able to accurately identify tree species and predict their distribution, as well as the distribution of tree mortality, across the landscape. Using a window size of 15 pixels and eight hidden convolutional layers, a CNN model classified the correct species of 713 individual trees from hyperspectral imagery with an average F-score of 0.87 and F-scores ranging from 0.67–0.95 depending on species. The CNN classification model performance increased from a combined F-score of 0.64 for the Red-Green-Blue model to a combined F-score of 0.87 for the hyperspectral model. The hyperspectral CNN model captures the species composition changes across {\~{}}700 meters (1935 to 2630 m) of elevation from a lower-elevation mixed oak conifer forest to a higher-elevation fir-dominated coniferous forest. High resolution tree species maps can support forest ecosystem monitoring and management, and identifying dead trees aids landscape assessment of forest mortality resulting from drought, insects and pathogens. We publicly provide our code to apply deep learning classifiers to tree species identification from geospatial imagery and field training data.},
author = {Fricker, Geoffrey A. and Ventura, Jonathan D. and Wolf, Jeffrey A. and North, Malcolm P. and Davis, Frank W. and Franklin, Janet},
doi = {10.3390/rs11192326},
file = {:home/marus200/Documents/library/Fricker et al/Fricker et al. - 2019 - A Convolutional Neural Network Classifier Identifies Tree Species in Mixed-Conifer Forest from Hyperspectral Ima.pdf:pdf},
journal = {Remote Sensing},
number = {19},
pages = {2326},
title = {{A Convolutional Neural Network Classifier Identifies Tree Species in Mixed-Conifer Forest from Hyperspectral Imagery}},
volume = {11},
year = {2019}
}
@article{Sothe2019a,
abstract = {The use of remote sensing data for tree species classification in tropical forests is still a challenging task, due to their high floristic and spectral diversity. In this sense, novel sensors on board of unmanned aerial vehicle (UAV) platforms are a rapidly evolving technology that provides new possibilities for tropical tree species mapping. Besides the acquisition of high spatial and spectral resolution images, UAV-hyperspectral cameras operating in frame format enable to produce 3D hyperspectral point clouds. This study investigated the use of UAV-acquired hyperspectral images and UAV-photogrammetric point cloud (PPC) for classification of 12 major tree species in a subtropical forest fragment in Southern Brazil. Different datasets containing hyperspectral visible/near-infrared (VNIR) bands, PPC features, canopy height model (CHM), and other features extracted from hyperspectral data (i.e., texture, vegetation indices-VIs, and minimum noise fraction-MNF) were tested using a support vector machine (SVM) classifier. The results showed that the use of VNIR hyperspectral bands alone reached an overall accuracy (OA) of 57{\%} (Kappa index of 0.53). Adding PPC features to the VNIR hyperspectral bands increased the OA by 11{\%}. The best result was achieved combining VNIR bands, PPC features, CHM, and VIs (OA of 72.4{\%} and Kappa index of 0.70). When only the CHM was added to VNIR bands, the OA increased by 4.2{\%}. Among the hyperspectral features, besides all the VNIR bands and the two VIs (NDVI and PSSR), the first four MNF features and the textural mean of 565 and 679 nm spectral bands were pointed out as more important to discriminate the tree species according to Jeffries-Matusita (JM) distance. The SVM method proved to be a good classifier for the tree species recognition task, even in the presence of a high number of classes and a small dataset.},
author = {Sothe, Camile and Dalponte, Michele and de Almeida, Cl{\'{a}}udia Maria and Schimalski, Marcos Benedito and Lima, Carla Luciane and Liesenberg, Veraldo and Miyoshi, Gabriela Takahashi and Tommaselli, Antonio Maria Garcia},
doi = {10.3390/rs11111338},
file = {:home/marus200/Documents/library/Sothe et al/Sothe et al. - 2019 - Tree Species Classification in a Highly Diverse Subtropical Forest Integrating UAV-Based Photogrammetric Point Clo.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Imaging spectroscopy,Photogrammetry,Support vector machine,Tree species mapping,Tropical biodiversity},
month = {jun},
number = {11},
pages = {1338},
title = {{Tree species classification in a highly diverse subtropical forest integrating UAV-based photogrammetric point cloud and hyperspectral data}},
url = {https://www.mdpi.com/2072-4292/11/11/1338},
volume = {11},
year = {2019}
}
@article{Berra2019,
abstract = {The monitoring of forest phenology in a cost-effective manner, at a fine spatial scale and over relatively large areas remains a significant challenge. To address this issue, unmanned aerial vehicles (UAVs) appear to be a potential new platform for forest phenology monitoring. This article assesses the potential of UAV data to track the temporal dynamics of spring phenology, from the individual tree to woodland scale, and cross-compare UAV results against ground and satellite observations, in order to better understand characteristics of UAV data and assess potential for use in validation of satellite-derived phenology. A time series of UAV data (5 cm spatial resolution, {\~{}}7 day temporal resolution) were acquired in tandem with an intensive ground campaign during the spring season of 2015 across a 15 ha mixed woodland. Phenophase transition dates were estimated at an individual tree-level using UAV time series of Normalized Difference Vegetation Index (NDVI) and Green Chromatic Coordinate (GCC) and validated against visual observations of tree phenology. UAV-derived start of season dates could be predicted with an accuracy of {\textless}1 week. The analysis was scaled to a plot level, where ground (visual assessment and understorey development), UAV and Landsat metrics were compared, indicating UAV data is effective for tracking canopy phenology, as opposed to ecosystem dynamics detected by satellites. The UAV data were used to automatically map phenological events for individual trees across the whole woodland, demonstrating that contrasting canopy phenological events can occur within the extent of a single Landsat pixel. This, and a large temporal gap in the Landsat series, accounted for the poor relationships found between UAV- and Landsat-derived phenometrics (R 2 {\textless} 0.50) in this study. An opportunity is now available to track very fine scale land surface changes over contiguous vegetation communities, providing information which could improve characterization of vegetation phenology at multiple scales.},
author = {Berra, Elias Fernando and Gaulton, Rachel and Barr, Stuart},
doi = {10.1016/j.rse.2019.01.010},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Consumer-grade camera,Drone,Forest phenology,Individual tree level,Land surface phenology},
month = {mar},
pages = {229--242},
publisher = {Elsevier},
title = {{Assessing spring phenology of a temperate woodland: A multiscale comparison of ground, unmanned aerial vehicle and Landsat satellite observations}},
url = {https://www.sciencedirect.com/science/article/abs/pii/S0034425719300100},
volume = {223},
year = {2019}
}
@inproceedings{Niculescu2018,
abstract = {{\textcopyright} SPIE. Downloading of the abstract is permitted for personal use only. Nowadays, optical and radar remote sensing data are increasingly used for land-cover/vegetation mapping and monitoring. Their technical capabilities and tools are improving all the time and provide more accurate results. By the recent arrival of the Sentinel-1 and Sentinel-2 series, available free, processing and methods of analysis must be increased more and more in the field of cartography. This paper aims to present vegetation mapping method in the Pays de Brest area by using a time series stacking of Sentinel-1, Sentinel-2 and SPOT-6 satellites data using the algorithm Random Forest supervised classification. The types of vegetation mapping in first time are those belonging to the major vegetation types, but especially those that can be observed on the processed images that are the Sentinel-1, Sentinel-2 series and SPOT-6. The types of classes considered for this study are: no vegetation, forest and undergrowth, moors and lawns, summer crops, winter crops, grassland and water. Several time series stacking has been made on that series containing 140 images radar representing different dates (2017) and the best combination method is to use both the two polarizations VV and VH to the calculation of the matrix of confusion. On the other hand, combinations of SAR images with different vegetation indices (NDVI, NDWI, S2rep, IRECI) calculated from the Images Sentinel-2 have been made. The series of times series stacking ends with combinations between SPOT-6 and Sentinel-1. The times series stacking Sentinel-1, Sentinel-2 and SPOT-6 are satisfactory, with an overall accuracy that reaches 93{\%}. Such precision is very good for data that are available free.},
author = {Niculescu, Simona and {Talab Ou Ali}, Halima and Billey, Antoine},
doi = {10.1117/12.2325546},
file = {:home/marus200/Documents/library/Niculescu, Talab Ou Ali, Billey/Niculescu, Talab Ou Ali, Billey - 2018 - Random forest classification using Sentinel-1 and Sentinel-2 series for vegetation monitoring i.pdf:pdf},
isbn = {9781510621497},
issn = {1996756X},
number = {October},
pages = {6},
title = {{Random forest classification using Sentinel-1 and Sentinel-2 series for vegetation monitoring in the Pays de Brest (France)}},
year = {2018}
}
@article{Wang2017a,
abstract = {{\textcopyright} 2017 by the authors. Remote-sensing phenology detection can compensate for deficiencies in field observations and has the advantage of capturing the continuous expression of phenology on a large scale. However, there is some variability in the results of remote-sensing phenology detection derived from different vegetation parameters in satellite time-series data. Since the enhanced vegetation index (EVI) and the leaf area index (LAI) are  the most widely used vegetation parameters for remote-sensing phenology extraction, this paper aims to assess the differences in phenological information extracted from EVI and LAI time series and to explore whether either index performs well for all vegetation types on a large scale. To this end, a GLASS (Global Land Surface Satellite Product)-LAI-based phenology product (GLP) was generated using the same algorithm as the MODIS (Moderate Resolution Imaging Spectroradiometer)-EVI phenology product (MLCD) over China from 2001 to 2012. The two phenology products were compared in China for different vegetation types and evaluated using ground observations. The results show that the ratio of missing data is 8.3{\%} for the GLP, which is less than the 22.8{\%} for the MLCD. The differences between the GLP and the MLCD become stronger as the latitude decreases, which also vary among different vegetation types. The start of the growing season (SOS) of the GLP is earlier than that of the MLCD in most vegetation types, and the end of the growing season (EOS) of the GLP is generally later than that of the MLCD. Based on ground observations, it can be suggested that the GLP performs better than the MLCD in evergreen needleleaved forests and croplands, while the MLCD performs better than the GLP in shrublands and grasslands.},
author = {Wang, Cong and Li, Jing and Liu, Qinhuo and Zhong, Bo and Wu, Shanlong and Xia, Chuanfu},
doi = {10.3390/s17091982},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Comparison,GLASS-LAI,Ground observations,MODIS-EVI,Remote-sensing phenology product},
number = {9},
title = {{Analysis of differences in phenology extracted from the enhanced vegetation index and the leaf area index}},
volume = {17},
year = {2017}
}
@misc{Yao2019b,
abstract = {The unmanned aerial vehicle (UAV) sensors and platforms nowadays are being used in almost every application (e.g., agriculture, forestry, and mining) that needs observed information from the top or oblique views. While they intend to be a general remote sensing (RS) tool, the relevant RS data processing and analysis methods are still largely ad-hoc to applications. Although the obvious advantages of UAV data are their high spatial resolution and flexibility in acquisition and sensor integration, there is in general a lack of systematic analysis on how these characteristics alter solutions for typical RS tasks such as land-cover classification, change detection, and thematic mapping. For instance, the ultra-high-resolution data (less than 10 cm of Ground Sampling Distance (GSD)) bring more unwanted classes of objects (e.g., pedestrian and cars) in land-cover classification; the often available 3D data generated from photogrammetric images call for more advanced techniques for geometric and spectral analysis. In this paper, we perform a critical review on RS tasks that involve UAV data and their derived products as their main sources including raw perspective images, digital surface models, and orthophotos. In particular, we focus on solutions that address the "new" aspects of the UAV data including (1) ultra-high resolution; (2) availability of coherent geometric and spectral data; and (3) capability of simultaneously using multi-sensor data for fusion. Based on these solutions, we provide a brief summary of existing examples of UAV-based RS in agricultural, environmental, urban, and hazards assessment applications, etc., and by discussing their practical potentials, we share our views in their future research directions and draw conclusive remarks.},
author = {Yao, Huang and Qin, Rongjun and Chen, Xiaoyu},
booktitle = {Remote Sensing},
doi = {10.3390/rs11121443},
file = {:home/marus200/Documents/library/Yao, Qin, Chen/Yao, Qin, Chen - 2019 - Unmanned Aerial Vehicle for Remote Sensing Applications—A Review.pdf:pdf},
issn = {20724292},
keywords = {Data analysis,Remote sensing applications,UAVs},
month = {jun},
number = {12},
pages = {1443},
title = {{Unmanned aerial vehicle for remote sensing applications - A review}},
url = {https://www.mdpi.com/2072-4292/11/12/1443},
volume = {11},
year = {2019}
}
@inproceedings{Berra2016,
abstract = {The aim of this study is to assess the potential of imagery acquired from an Unmanned Aerial Vehicle (UAV) to track seasonal changes in leaf canopy at individual tree level. UAV flights were carried out over a deciduous woodland during the spring season of 2015, from which a temporal series of 5 cm spatial resolution orthophotos was generated. Initial results are presented in this paper. Four trees with different observed Start of Season (SOS) dates were selected to monitor UAV-derived Green Chromatic Coordinate (GCC). The chronological order when sudden increases of GCC values occurred matched with the chronological order of observed SOS. Trees with later observed SOS presented GCC values increasing slowly over time, which were associated with development of understory vegetation. It is concluded that UAV imagery has the potential to track leaf phenology at the individual tree level, but further studies are necessary to better understand this new level of information detected from UAVs.},
author = {Berra, E F and Gaulton, R and Barr, S},
booktitle = {2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
doi = {10.1109/IGARSS.2016.7729904},
issn = {2153-7003},
keywords = {autonomous aerial vehicles,digi,vegetation mapping},
pages = {3496--3499},
title = {{Use of a digital camera onboard a UAV to monitor spring phenology at individual tree level}},
year = {2016}
}
@article{Motohka2010,
abstract = {We evaluated the use of the Green-Red Vegetation Index (GRVI) as a phenological indicator based on multiyear stand-level observations of spectral reflectance and phenology at several representative ecosystems in Japan. The results showed the relationships betweenGRVI values and the seasonal change of vegetation and ground surface with high temporal resolution. We found that GRVI has the following advantages as a phenological indicator: (1) GRVI = 0 can be a site-independent single threshold for detection of the early phase of leaf green-up and the middle phase of autumn coloring, and (2) GRVI can show a distinct response to subtle disturbance and the difference of ecosystem types.},
author = {Motohka, Takeshi and Nasahara, Kenlo Nishida and Oguma, Hiroyuki and Tsuchida, Satoshi},
doi = {10.3390/rs2102369},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Digital camera,Green-Red Vegetation Index,Phenological eyes network,Phenology,Remote sensing,Spectral reflectance},
number = {10},
pages = {2369--2387},
title = {{Applicability of Green-Red Vegetation Index for remote sensing of vegetation phenology}},
volume = {2},
year = {2010}
}
@article{Persson2018,
abstract = {The Sentinel-2 program provides the opportunity to monitor terrestrial ecosystems with a high temporal and spectral resolution. In this study, a multi-temporal Sentinel-2 data set was used to classify common tree species over a mature forest in central Sweden. The tree species to be classified were Norway spruce (Picea abies), Scots pine (Pinus silvestris), Hybrid larch (Larix × marschlinsii), Birch (Betula sp.) and Pedunculate oak (Quercus robur). Four Sentinel-2 images from spring (7 April and 27 May), summer (9 July) and fall (19 October) of 2017 were used along with the Random Forest (RF) classifier. A variable selection approach was implemented to find fewer and uncorrelated bands resulting in the best model for tree species identification. The final model resulting in the highest overall accuracy (88.2{\%}) came from using all bands from the four image dates. The single image that gave the most accurate classification result (80.5{\%}) was the late spring image (27 May); the 27 May image was always included in subsequent image combinations that gave the highest overall accuracy. The five tree species were classified with a user's accuracy ranging from 70.9{\%} to 95.6{\%}. Thirteen of the 40 bands were selected in a variable selection procedure and resulted in a model with only slightly lower accuracy (86.3{\%}) than that using all bands. Among the highest ranked bands were the red edge bands 2 and 3 as well as the narrow NIR (near-infrared) band 8a, all from the 27 May image, and SWIR (short-wave infrared) bands from all four image dates. This study shows that the red-edge bands and SWIR bands from Sentinel-2 are of importance, and confirms that spring and/or fall images capturing phenological differences between the species are most useful to tree species classification.},
author = {Persson, Magnus and Lindberg, Eva and Reese, Heather},
doi = {10.3390/rs10111794},
file = {:home/marus200/Documents/library/Persson, Lindberg, Reese/Persson, Lindberg, Reese - 2018 - Tree species classification with multi-temporal Sentinel-2 data.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Boreo-nemoral,Multi-temporal,Phenology,Random Forest,Sentinel-2,Tree species classification,Variable selection},
number = {11},
pages = {1--17},
title = {{Tree species classification with multi-temporal Sentinel-2 data}},
volume = {10},
year = {2018}
}
@article{Grabska2019,
abstract = {Accurate information regarding forest tree species composition is useful for a wide range of applications, both for forest management and scientific research. Remote sensing is an effcient tool for collecting spatially explicit information on forest attributes. With the launch of the Sentinel-2 mission, new opportunities have arisen for mapping tree species owing to its spatial, spectral, and temporal resolution. The short revisit cycle (five days) is crucial in vegetation mapping because of the reflectance changes caused by phenological phases. In our study, we evaluated the utility of the Sentinel-2 time series for mapping tree species in the complex, mixed forests of the Polish Carpathian Mountains. We mapped the following nine tree species: common beech, silver birch, common hornbeam, silver fir, sycamore maple, European larch, grey alder, Scots pine, and Norway spruce. We used the Sentinel-2 time series from 2018, with 18 images included in the study. Different combinations of Sentinel-2 imagery were selected based on mean decrease accuracy (MDA) and mean decrease Gini (MDG) measures, in addition to temporal phonological pattern analysis. Tree species discrimination was performed using the Random Forest classification algorithm. Our results showed that the use of the Sentinel-2 time series instead of single date imagery significantly improved forest tree species mapping, by approximately 5-10{\%} of overall accuracy. In particular, combining images from spring and autumn resulted in better species discrimination.},
author = {Grabska, Ewa and Hostert, Patrick and Pflugmacher, Dirk and Ostapowicz, Katarzyna},
doi = {10.3390/rs11101197},
file = {:home/marus200/Documents/library/Grabska et al/Grabska et al. - 2019 - Forest stand species mapping using the sentinel-2 time series.pdf:pdf},
issn = {20724292},
journal = {Remote Sensing},
keywords = {Forest,Polish carpathians,Random forest,Sentinel-2,Time series},
number = {10},
pages = {1--24},
title = {{Forest stand species mapping using the sentinel-2 time series}},
volume = {11},
year = {2019}
}
@book{FoodandAgricultureOrgansiationoftheUnitedNations2015,
abstract = {sustainably managed forests provide essential goods and services and thus play a vital part in sustainable development. reliable and up-to-date information on the state of forest resources is crucial to support decision-making for investment and policymaking in forestry and sustainable development. Fao, at the request of its member countries, regularly monitors the world´s forests and their management and uses through the Global Forest resources assessment (Fra). more information on the Fra 2015 process, other publications and online database is available on the Fra web site (www.fao.org/forestry/fra ). the Fra process is coordinated by the Forestry Department at Fao headquarters in rome in coordination with partners in the collaborative Forest resources Questionnaire (cFrQ). these six partners are: the central african Forest commission (comIFac/ oFac), Fao, Forest euroPe, the International tropical timber organization (Itto), the montr{\'{e}}al Process, and the united nations economic commission for europe (unece).},
author = {{Food and Agriculture Organsiation of the United Nations}},
booktitle = {Desk Reference},
doi = {10.1002/2014GB005021},
file = {:home/marus200/Documents/library/Food and Agriculture Organsiation of the United Nations/Food and Agriculture Organsiation of the United Nations - 2015 - Global Forest Resources Assessment 2015.pdf:pdf},
isbn = {9789251088210},
pages = {244},
title = {{Global Forest Resources Assessment 2015}},
year = {2015}
}
@article{Klosterman2017,
abstract = {Plant phenology is a sensitive indicator of the effects of global change on terrestrial ecosystems and controls the timing of key ecosystem functions including photosynthesis and transpiration. Aerial drone imagery and photogrammetric techniques promise to advance the study of phenology by enabling the creation of distortion-free orthomosaics of plant canopies at the landscape scale, but with branch-level image resolution. The main goal of this study is to determine the leaf life cycle events corresponding to phenological metrics derived from automated analyses based on color indices calculated from drone imagery. For an oak-dominated, temperate deciduous forest in the northeastern USA, we find that plant area index (PAI) correlates with a canopy greenness index during spring green-up, and a canopy redness index during autumn senescence. Additionally, greenness and redness metrics are significantly correlated with the timing of budburst and leaf expansion on individual trees in spring. However, we note that the specific color index for individual trees must be carefully chosen if new foliage in spring appears red, rather than green—which we observed for some oak trees. In autumn, both decreasing greenness and increasing redness correlate with leaf senescence. Maximum redness indicates the beginning of leaf fall, and the progression of leaf fall correlates with decreasing redness. We also find that cooler air temperature microclimates near a forest edge bordering a wetland advance the onset of senescence. These results demonstrate the use of drones for characterizing the organismic-level variability of phenology in a forested landscape and advance our understanding of which phenophase transitions correspond to color-based metrics derived from digital image analysis.},
author = {Klosterman, Stephen and Richardson, Andrew D.},
doi = {10.3390/s17122852},
file = {:home/marus200/Documents/library/Klosterman, Richardson/Klosterman, Richardson - 2017 - Observing spring and fall phenology in a deciduous forest with aerial drone imagery.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Drone,Harvard Forest,Leaf color,Phenology,Plant area index,UAV},
month = {dec},
number = {12},
publisher = {MDPI AG},
title = {{Observing spring and fall phenology in a deciduous forest with aerial drone imagery}},
volume = {17},
year = {2017}
}
@article{Mngadi2019,
abstract = {AbstractThe successful launch and operation of the Sentinel satellite platform has provided access to freely available remotely sensed data useful for commercial forest species discrimination. Sentinel – 1 (S1) with a synthetic aperture radar (SAR) sensor and Sentinel – 2 (S2) multi-spectral sensor with additional and strategically positioned bands offer great potential for providing reliable information for discriminating and mapping commercial forest species. In this study, we sought to determine the value of S1 and S2 data characteristics in discriminating and mapping commercial forest species. Using linear discriminant analysis (LDA) algorithm, S2 multi-spectral imagery showed an overall classification accuracy of 84{\%} (kappa = 0.81), with bands such as the red-edge (703.9–740.2 nm), narrow near infrared (835.1–864.8 nm), and short wave infrared (1613.7–2202.4 nm) particularly influential in discriminating individual forest species stands. When Sentinel 2's spectral wavebands were fused with Sentinel 1's (SAR) VV and VH polarimetric modes, overall classification accuracies improved to 87{\%} (kappa = 0.83) and 88{\%} (kappa = 0.85), respectively. These findings demonstrate the value of combining Sentinel's multispectral and SAR structural information characteristics in improving commercial forest species discrimination. These, in addition to the sensors free availability, higher spatial resolution and larger swath width, offer unprecedented opportunities for improved local and large scale commercial forest species discrimination and mapping.},
author = {Mngadi, Mthembeni and Odindi, John and Peerbhay, Kabir and Mutanga, Onisimo},
doi = {10.1080/10106049.2019.1585483},
journal = {Geocarto International},
number = {0},
pages = {1--12},
publisher = {Taylor {\&} Francis},
title = {{Examining the effectiveness of Sentinel-1 and 2 imagery for commercial forest species mapping}},
url = {https://doi.org/10.1080/10106049.2019.1585483},
volume = {0},
year = {2019}
}
@article{Wan2018,
abstract = {Remote estimation of flower number in oilseed rape under different nitrogen (N) treatments is imperative in precision agriculture and field remote sensing, which can help to predict the yield of oilseed rape. In this study, an unmanned aerial vehicle (UAV) equipped with Red Green Blue (RGB) and multispectral cameras was used to acquire a series of field images at the flowering stage, and the flower number was manually counted as a reference. Images of the rape field were first classified using K-means method based on Commission Internationale de l'{\'{E}}clairage (CIE) L*a*b* space, and the result showed that classified flower coverage area (FCA) possessed a high correlation with the flower number (r2 = 0.89). The relationships between ten commonly used vegetation indices (VIs) extracted from UAV-based RGB and multispectral images and the flower number were investigated, and the VIs of Normalized Green Red Difference Index (NGRDI), Red Green Ratio Index (RGRI) and Modified Green Red Vegetation Index (MGRVI) exhibited the highest correlation to the flower number with the absolute correlation coefficient (r) of 0.91. Random forest (RF) model was developed to predict the flower number, and a good performance was achieved with all UAV variables (r2 = 0.93 and RMSEP = 16.18), while the optimal subset regression (OSR) model was further proposed to simplify the RF model, and a better result with r2 = 0.95 and RMSEP = 14.13 was obtained with the variable combination of RGRI, normalized difference spectral index (NDSI (944, 758)) and FCA. Our findings suggest that combining VIs and image classification from UAV-based RGB and multispectral images possesses the potential of estimating flower number in oilseed rape.},
author = {Wan, Liang and Li, Yijian and Cen, Haiyan and Zhu, Jiangpeng and Yin, Wenxin and Wu, Weikang and Zhu, Hongyan and Sun, Dawei and Zhou, Weijun and He, Yong},
doi = {10.3390/rs10091484},
journal = {Remote Sensing},
keywords = {flower number,image classification,oilseed,rape,rgb and multispectral camera,uav,unmanned aerial vehicle,vegetation indices},
number = {9},
pages = {1484},
title = {{Combining UAV-Based Vegetation Indices and Image Classification to Estimate Flower Number in Oilseed Rape}},
volume = {10},
year = {2018}
}
