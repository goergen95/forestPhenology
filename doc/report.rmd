---
output: 
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    df_print: kable
    latex_engine: pdflatex
    fig_caption: true
bibliography: ForestPhenology.bib
csl: elsevier-harvard.csl
title: "UAV imagery based tree species classification in the Marburg OpenForest"
author: 
- Darius A. Görgen
- Tobias Koch
- Marvin Müsgen
- Eike Schott
date: "`r format(Sys.time(), '%B %d, %Y')`"

abstract: "The monitoring of forests environments is of crucial importance since they serve as natural habitats and constitute a main source of biological diversity. Yet, it is very costly and labor intensive to monitor forests by traditional means. Recently, there have been several attempts to use UAV-borne imagery in forest monitoring since these images can be obtained at low cost and can come with both, high spatial and temporal resolution which enable scientists and practitioners to comprehensively monitor forest environments. Tree species identification is primary interest, since the identification of species allows to draw conclusions about the structure and biodiversity in given areas of a forest. When using simple RGB images, species classification still remains a challenge. In this paper we present our results of an experiment exploring the influence of spatial resolution of RGB imagery, artificially derived vegetation indices as well as seasonal parameters on the accuracy of tree species classification within the Marburg OpenForest. We used a resolution of 5 cm, 10 cm, 15 cm, and 25 cm in a forwar-feature-selection based on the RandomForest classification algorithm. Additionally we tested the obtained accuracy when only mono-temporal or multi-temporal variables are included as well as both types of variables. Our results show that ..."

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tmap)
library(caret)
library(raster)
library(stringr)
library(ggplot2)
```

# Introduction

Forests environments provide valuabel services to the human well being as well as 
supporting services to the function of ecosystems. Additionally, they count to 
the main biodiversity hotspots on earth [@Brockerhoff2017]. However, the most recent
Global Forest Ressource Assessment of the FAO states, that the global forest area
shrinked between 1990 and 2015 from 31.6% of the global land cover to 30.6%, or in 
other numbers from 4,128 Mio. ha to 3,999 Mio. ha - a decrease of 3.1% [@FoodandAgricultureOrgansiationoftheUnitedNations2015].
Simultaniously, the percentage of planted trees increased by over 105 Mio. ha, 
reducing the share of natural forest areas. Over the last decades, we can find 
scholary interests on ecosystem services and functions which are sustained by forests,
mainly the habitat provision for endangered or native species, the provision of 
material goods such as wood biomass, soil formation and composition, as well as 
climatic regulation functions, such as carbon sequestration [@Brockerhoff2017].
One of the main critical variables in assessing the quality of forest envrionments,
their biodiversity, and their structural attributes is the tree species, either on
the individual tree level or the dominating species for coarser areas of interest. 

Identifying tree species, however, on an operative scale for larger areas, remains a challenge.
Recently, different remote sensing approaches proved that tree species identification
from above the earth's surface is feasiable, but there still remain significant 
trade-offs between the costs, computational demand and spatial-temporal resolution of
remotly sensed imagery.


# Data and Method

In this project, AgisoftPhotoScan (???) in the version (???) was used to process the UAV imagery. Agisoft Photoscan Professional is anaffordable 3D reconstruction software from the Russian company Agisoft LLC (Agisoft, 2018) for the generation of dense point clouds and photogrammetric products such as orthorectified mosaics and DSM derived from images. Photoscan has the advantage to provide a simple workflow, from performing bundle block adjustment to calibrate the camera and orientate images after automatic tie point measurements, geo-referencing by measuring ground control points, concluding with the computation of a dense point cloud and requested final products (Mayer et al. 2018 ???? Mendely hinzuf?gen). The Airborne system (???Drohnenname) was used to acquire the UAV imagery using a commercial goPro (???Model + Objektiv. In (??? Anzahl flights) flight campaigns with a flight altitude of (40 meters???), (???Anzahlfotos) photos were acquired. The internal GPS of the GoPro was used for geotagging the images. A post referencing enabled a better processing of the images in SFM software (Version???) and more accurate orthophotos without manual referencing in Photoscan.  Photo Alignment is a process in PS for image matching and bundle block adjustment in an arbitrary system. It generates a sparse point cloud as well as the interior and exterior orientation parameters of all images in that system, including systematic error compensation such as non-linear lens distortions. Prior to the adjustment, the tie points are automatically measured by detecting and matching features in overlapping images resulting in a sparse point cloud (Mayer et al. 2018??? Mendely hinzuf?gen).The settings in this project were chosen as follows:
- General: Accuracy: Medium; Generec preselection: yes; Reference preselection: yes
- Advances: Key Piont limit: 40000; Tie point limit: 4000; apply mask: no; Adaptive camera model fitting: yes

Sparse cloud filtering was performed under the following settings:
-gradual Selection: reprojection error: 0.26; reconstruction uncertainty: 189.461; projection accuracy:12.4621; reconstruction uncertainty:6.72951; reprojectionerror:0.122199

Based on the information of the point cloud (Sparse Cloud, Dense Cloudetc  ...) PhotoScan can construct a polygon model (Mesh) (Agisoft 2018??? Mendeley hinzuf?gen) In this Project the Mesh was build by following setting:
- General: surface type: Height field (2.5D); source data: sparse cloud; face count: medium
- advanced: Interpolation: enabled; Point classes: all; calculate vertex colors

The different pixel values from different photos are combined by the Mosaic type in the final texture. Mosiac type implies a two-step approach. Low frequency components are blended for overlapping images to avoid seam line problems. The high-frequency component, on the other hand, which is responsible for the image details, is only captured from a single image.


In total we worked on 6 images which were obtained between the end of April to 
the end of June. In the mitlatitudes of central Europe these are the months of vegetational
peak of mixed forests. We calculated a selection of RGB-based vegetational indices for each
of the images as well as seasonal statistics which describe the development of these indices
in the course of the vegetation period.

- UAV orthoimages, AgiSoft (how-to), flight height
- pre-process: crop to AOI, spatial aggregations different resolutions, indices, season parameters
- tree shape: differential GPS points, >= 40cm DBH, 2m buffer, squares -> species
- RF model, 5-fold cross validation, training vs. testing, kappa & accuracy,
- plots predictors (all, indices, seasons) vs. resolutions 


```{r dates-table, echo=F, tab.cap="Days of UAV overpass.",}
dates = unique(readRDS("../../data/resampled/dates.rds"))
dates = as.Date(dates, format = "%Y_%m_%d" )
dates = data.frame(Dates=dates)
knitr::kable(dates, align="l", caption = "Dates of the UAV overpasses.",)

```
```{r cv_visualization, warning=F,message=F,echo=F}
trees = rgdal::readOGR("../../data/trees_buffer.shp" )
trees@data$polID = seq(nrow(trees@data))
set.seed(1899)
index = caret::createDataPartition(y = trees@data$polID, p = .70, list = FALSE)
pred = trees@data[-index, ]
ind = CAST::CreateSpacetimeFolds(pred, spacevar = "polID", k = 5)

trees@data$train[index] = 0
trees@data$train[-index] = 1

trees@data$cv1[trees$id %in%pred$id[ind$index[[1]]]] = 1
trees@data$cv1[trees$id %in%pred$id[ind$indexOut[[1]]]] = 0

trees@data$cv2[trees$id %in%pred$id[ind$index[[2]]]] = 1
trees@data$cv2[trees$id %in%pred$id[ind$indexOut[[2]]]] = 0

trees@data$cv3[trees$id %in%pred$id[ind$index[[3]]]] = 1
trees@data$cv3[trees$id %in%pred$id[ind$indexOut[[3]]]] = 0

trees@data$cv4[trees$id %in%pred$id[ind$index[[4]]]] = 1
trees@data$cv4[trees$id %in%pred$id[ind$indexOut[[4]]]] = 0

trees@data$cv5[trees$id %in%pred$id[ind$index[[5]]]] = 1
trees@data$cv5[trees$id %in%pred$id[ind$indexOut[[5]]]] = 0

rgbimage = raster::stack("../../data/resampled/res25.tif")
rgb_names = readRDS("../../data/resampled/names_RGB_stack.rds")
names(rgbimage) = rgb_names 

rgbimage = rgbimage[[13:15]]


tm_shape(rgbimage)+
  tm_rgb()+
  tm_shape(trees)+
  tm_fill(col = "train", palette = "RdBu")


tm_shape(rgbimage)+
  tm_rgb()+
  tm_shape(trees, col = c("red","blue","grey"))+
  tm_polygons(c("cv1","cv2","cv3","cv4","cv5"))

```

# Results


```{r result_plots, echo=F, warning=F, message=F}

models = list.files("../results", pattern = "\\.rds$", full.names = T)

getModelMetric <- function(model, metric){
    decomp = str_split(str_split(model, "/")[[1]][3], "_")[[1]]
    if (length(decomp) == 2){
      res = str_sub(decomp[2],4,5)
      type = "all"
    } else {
      res =  str_sub(decomp[3],4,5)
      type = decomp[2]
    }
    
    model = readRDS(model)
    besthyper = as.numeric(model$bestTune)
    if (!metric %in% c("Kappa", "Accuracy")) stop("chosen metric not valid.")
    if (metric == "Kappa"){
      metricVal = model$results$Kappa[which(model$results$mtry == besthyper)]}
    if (metric == "Accuracy"){
      metricVal = model$results$Accuracy[which(model$results$mtry == besthyper)]}
    df_return = data.frame(resolution=res, type=type, metric=metricVal)
    names(df_return)[3] = metric
   return(df_return)
  }
  
kappas = do.call("rbind", lapply(models, getModelMetric, metric="Kappa"))

ggplot(data = kappas, aes(x=resolution)) +
  geom_point(aes(y=Kappa, shape=type, col=type), size=2)+
  theme_minimal()


accuracies = do.call("rbind", lapply(models, getModelMetric, metric="Accuracy"))

ggplot(data = accuracies, aes(x=resolution)) +
  geom_point(aes(y=Accuracy, shape=type, col=type), size=2)+
  theme_minimal()

```


# Sources
Example citation [@Ulsig2017a].


