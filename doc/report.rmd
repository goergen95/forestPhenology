---
output: 
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    df_print: kable
    latex_engine: pdflatex
    fig_caption: true
    keep_tex: true
header-includes:
  \usepackage{float}
bibliography: ["ForestPhenology.bib", "r-bib.bib"] 
csl: elsevier-harvard.csl
nocite: |
  @Broge2001, @Gobron2000, @Wan2018, @Rowan2003, @Laboratory2015, @Sonnentag2012, @Richardson2009, @Hunt2012
title: "UAV imagery based tree species classification in the Marburg OpenForest"
author: 
- Darius A. Görgen
- Tobias Koch
- Marvin Müsgen
- Eike Schott
date: "`r format(Sys.time(), '%B %d, %Y')`"

abstract: "The monitoring of forests environments is of crucial importance since they serve as natural habitats and constitute a main source of biological diversity on the planet. Yet, it is very costly and labor intensive to monitor forests by traditional means and classical remote sensing technologies restrict the analysis to the regional level. To overcome these challenges there have been several attempts to use UAV-borne imagery in forest monitoring. By the use of drones images can be obtained at low cost and can be associated with both, high spatial and temporal resolution. This enables scientists and practitioners to comprehensively monitor forest environments. Tree species identification is primary interest, since the identification of species allows to draw conclusions about the structure and biodiversity in given areas of a forest. When using simple RGB images, species classification still remains a challenge. In this paper we present our results of an experiment exploring the influence of spatial resolution of RGB imagery, artificially derived vegetation indices as well as seasonal parameters on the accuracy of tree species classification within the Marburg OpenForest. We used a resolution of 10 cm, 15 cm, and 25 cm in a forward-feature-selection based on the Random Forest classification algorithm. Additionally we tested the obtained accuracy when only mono-temporal or multi-temporal variables are included as well as both types of variables. Our results show that ..."

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.pos = "H", fig.align="center")
library(tmap)
library(caret)
library(raster)
library(stringr)
library(ggplot2)
library(dplyr)
library(purrr)
library(rgdal)
library(knitr)
library(kableExtra)
library(tidyr)
library(png)
library(forcats)
library(randomForest)
trees = readOGR("../../data/trees_buffer.shp")
```

# Introduction

Forests environments provide valuable services to the human well being as well as 
supporting services to the function of ecosystems. Additionally, they count to 
the main biodiversity hotspots on earth [@Brockerhoff2017]. However, the most recent
Global Forest Resource Assessment of the FAO states, that the global forest area
shrinked between 1990 and 2015 from 31.6% of the global land cover to 30.6%, or in 
other numbers from 4,128 Mio. ha to 3,999 Mio. ha - a decrease of 3.1% [@FoodandAgricultureOrgansiationoftheUnitedNations2015].
Simultaneously, the percentage of planted trees increased by over 105 Mio. ha, 
reducing the share of natural forest areas. Over the last decades, we can find growing
scholar interests on ecosystem services and functions which are sustained by forests,
mainly the habitat provision for endangered or native species, the provision of 
material goods such as wood biomass, soil formation and composition, as well as 
climatic regulation functions, such as carbon sequestration [@Brockerhoff2017].
One of the main critical variables in assessing the quality of forest environments,
their biodiversity, and their structural attributes is the tree species, either on
the individual tree level or the dominating species for coarser areas of interest. 

Identifying tree species, however, on an operative scale for larger areas, remains a challenge.
Recently, different remote sensing approaches proved that tree species identification
from above the earth's surface is feasible, but there still remain significant 
trade-offs between the costs, computational demand and spatial-temporal resolution of
remotely sensed imagery. Some studies have used satellite imagery which most frequently also
include information in the infrared spectrum [@Zhang2003; @Elatawneh2013; @Ulsig2017a; @Persson2018; @Grabska2019]
but generally shows a relatively low spatial resolution limiting the analysis to a 
level of stand rather than individuals. Additionally, depended on the platform's orbit
and current weather conditions, the temporal resolution may vary significantly and is 
not completely planable.

One technology to partly overcome these restrictions is the use of Radio Detection And
Ranging (RADAR) sensors which show a lower dependency of data quality to the presence
of clouds and fog. Recently, multi-temporal data from Sentinel-1 has been used in 
conjunction with spectral data to not only improve the species classification accuracy but
also to retrieve additional parameters important to forest monitoring such as forest type, 
stand density, annual phenology, and biomass production among others [@Frison2018; @Niculescu2018; @Dostalova2018; @Mngadi2019].
However promising these advances, the analysis are most commonly restricted to regional analysis
of forest structures. On a more localized level, high resolution satellite data is 
either not available or associated with very high costs. With the rapid development of
unmanned aerial vehicles (UAV) during the last years and a significant decrease in price for
this technology, new approaches to monitor forest structures on a very local level
have recently emerged [@Yao2019b].  

UAVs serve as an aerial platform of different kind of sensors which can range from
LidAR [@Fricker2019], hyper- and multi spectral sensors [@Marques2019a; @Berra2019] 
as well as simple RGB cameras [@Natesan2019]. A broad methodology to obtain species information for 
single tree individuals has been developed integrating the calculation of various 
vegetation indices from mono- and multi-temporal imagery and the use of machine learning
models to derive a relationship between the measured variables and the 
tree species.
@Berra2016 used the Green Chromatic Coordinate to monitor the Start-of-Season for
four different tree species in deciduous woodland suggesting that UAV imagery 
can contribute to investigate the phenological status of individual trees.
@Klosterman2017 were able to estimate phenological status on the leaf-level
based on the calculation of the green and red chromatic coordinate (GCC and RCC) 
during spring and autumn to bud burst and leaf expansion as well as leaf senescence.
@Natesan2019 used Residual Neural Networks to classify three different tree species based on RGB
imagery obtained over the course of three years and achieved a classification accuracy
of about 80%, and an accuracy of 51% when only the data of single years was used. 
@Fricker2019 used hyperspectral images obtained by a UAV and a Convolutional Neural
Network to classify tree species. They also underwent an experiment which only included RGB
data. The hyperspectral data achieved an F-score of 0.87, while the RGB data achieved 
a score of 0.64 in a dominantly coniferous forest.

Additionally, the development of structure-from-motion algorithms 
to get 3D information from 2D RGB imagery taken from slightly different angles 
have enriched the analysis of forest structures from low-cost sensors. 
@Nevalainen2017 used RGB images and an automated matching technique to obtain 
point clouds at a 5cm resolution. Coupled with hyperspectral imagery this allowed 
the tree species classification to an accuracy at 95%.
@Yan2018a compared their approach of retrieving tree crowns from RGB images with
crowns delineated from LiDAR data and report an accuracy at about 90%. @Krause2019a 
were able to retrieve individual tree height based on a photogrammetric point-cloud 
with an RMSE at about 2-3 %. @Brieger2019a used RGB derived point clouds at
different study sites in Siberia and achieved an accuracy of 67.1% in delineating 
individual tree crowns and an RMSE of 18.46% for tree height. @Sothe2019a used
hyperspectral images for tree delineation and classification in subtropical rain forests
and achieved and Kappa score of 0.7 (overall accuracy of 72.4%) by combining spectral
raw data, indices as well as structural parameters in the classification process using 
a support-vector machine. 

However, little efforts have been done to structurally investigate the impact of decreasing
spatial resolution on the classification accuracy as well as the impact of
the integration of seasonal parameters derived from multiple mono-temporal observations.
Here, we strictly limit our analysis to the investigation of these two thematic 
blocs and deliberately exclude other factors such as structural variables obtained
from point clouds. We solely focus on the analysis of the dynamic in predictive potential 
of RGB derived mono- and multi-temporal variables to model tree species with 
changing spatial resolution. 

To this end we use the RGB imagery obtained by multiple overflights during the year 
2019 from a study side located within the Marburg University forest which is part
of the research project [Natur 4.0](https://www.uni-marburg.de/en/fb19/natur40/). 
This forest is used as a joint research area for a project between several German universities 
and research institutes and sets out to investigate the potential of sensor technology for 
biodiversity and natural resource management in natural environments forests. 
We artificially decreased the spatial resolution of aerial imagery obtained in this
area resulting in three different target resolutions of 10, 15, and 25 cm. 
For every single overflight we calculated a series of RGB indices on a pixels basis. 
Additionally, we calculate descriptive statistics (mean, maximum, minimum, amplitude, etc.) 
for each index over the course of the year to include information about the 
seasonality of the phenological development.

The resulting input data is used to establish a total of nine distinct random forest models, one
for each resolution including either only mono-temporal or seasonal predictor variables 
or both types of variables. On the basis of a forward-feature selection
the variables which carry the most relevant information content for the tree species
classification are then selected and used in the species prediction. The evaluation
of the classification accuracies is compared on a pixel and object basis to draw
conclusions on the importance of spatial resolution as well as the importance
of mono- vs. multi-temporal input data.


# Data and Methods

## Study Area

The study area is located at 50.8°N 8.7°E in the German low mountain range in Hesse.
It is part of the University Forest Caldern where the recently initiated joint research
project Natur 4.0 aims at investigating the use of networked sensor technology for 
biodiversity and ecosystem management and protection. It is in this context, that the aerial images 
which we used here were obtained in an observation campaign during 2019 (see Tab. 1).
The area is approximately 37,500 m² and continuously covered by trees. In this
specific location, only two distinct species are present with stem diameters
at breast height (DBH) greater than 40 cm, namely _fagus sylvatica_ and
_quercus robur_.


```{r plot_aoi, warning=F, message=F,fig.cap="RGB image of the study area from May 16th 2019 with central positions of tree stems superimposed (Coordinates are presented in UTM32N).", out.width="70%", fig.pos="H"}

rgb = brick("../../data/resampled/res25.tif")[[10:12]]
projection = "+proj=utm +zone=32 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"

tm_shape(rgb)+
  tm_rgb()+
  tm_shape(trees)+
  tm_borders(lwd=1, lty="solid", col="black")+
  tm_graticules(ticks=T, projection=projection, lines=F, 
                labels.format=list(digits=0),
                n.y=6, n.x=4)+
  tm_layout(inner.margins = 0)
```

## Pre-Processing of the UAV orthoimages


In this project, AgisoftPhotoScan was used to process the UAV imagery. Agisoft Photoscan Professional is an affordable 3D reconstruction software from the Russian company Agisoft LLC @Agisoft2019 for the generation of dense point clouds and photogrammetric products such as orthorectified mosaics and DSM derived from images. Photoscan has the advantage to provide a simple workflow, from performing bundle block adjustment to calibrate the camera and orientate images after automatic tie point measurements, geo-referencing by measuring ground control points, concluding with the computation of a dense point cloud and requested final products @Mayer2018. The Airborne system was used to acquire the UAV imagery using a commercial GoPro in several flight campaigns with a flight altitude of 40 meters The internal GPS of the GoPro was used for geotagging the images. A post referencing enabled a better processing of the images in SFM software and more accurate orthophotos without manual referencing in Photoscan.  Photo Alignment is a process in PS for image matching and bundle block adjustment in an arbitrary system. It generates a sparse point cloud as well as the interior and exterior orientation parameters of all images in that system, including systematic error compensation such as non-linear lens distortions. Prior to the adjustment, the tie points are automatically measured by detecting and matching features in overlapping images resulting in a sparse point cloud @Mayer2018.The settings in this project were chosen as follows:
- General: Accuracy: Medium; Generic preselection: yes; Reference preselection: yes
- Advances: Key Point limit: 40000; Tie point limit: 4000; apply mask: no; Adaptive camera model fitting: yes

Sparse cloud filtering was performed under the following settings:
-gradual Selection: reprojection error: 0.26; reconstruction uncertainty: 189.461; projection accuracy:12.4621; reconstruction uncertainty:6.72951; reprojection error:0.122199

```{r dates-table, tab.cap="Days of UAV overpasses.",}
dates = unique(readRDS("../../data/resampled/dates.rds"))
dates = as.Date(dates, format = "%Y_%m_%d" )
dates = data.frame(Dates=dates)
knitr::kable(dates, format = "latex", linesep="", align = "l", booktabs = T,
             caption = "Dates of the UAV overpasses.") %>%
  kable_styling(latex_options = c("hold_position")) %>%
  row_spec(0,bold=TRUE)
```

Based on the information of the point cloud (Sparse Cloud, Dense Cloud etc  ...) PhotoScan can construct a polygon model (Mesh) @Agisoft2019. In this Project the Mesh was build by following setting:
- General: surface type: Height field (2.5D); source data: sparse cloud; face count: medium
- advanced: Interpolation: enabled; Point classes: all; calculate vertex colors

The different pixel values from different photos are combined by the Mosaic type in the final texture. Mosaic type implies a two-step approach. Low frequency components are blended for overlapping images to avoid seam line problems. The high-frequency component, on the other hand, which is responsible for the image details, is only captured from a single image.


In total we worked on 6 images which were obtained between the end of April to 
the end of June. In the mid latitudes of central Europe these are the months of vegetational
peak of mixed forests. We calculated a selection of RGB-based vegetational indices for each
of the images as well as seasonal statistics which describe the development of these indices
in the course of the vegetation period.

The images provided by the "Nature 4.0" project could not be geotagged completely cleanly at the start of our investigation. Therefore, some images are not optimally overlaid, which leads to image distortions. The following figure shows the image distortion by looking at the transporter in the image.

```{r Image distortion, echo=F, message=F, warning=F, fig.cap="Exempelary display of the image distortion in the dataset."}
imgr <- stack("Bild_verzerrung.tif")
plotRGB(imgr)

```


## Tree species data

With the use of a differential GPS the position of tree stems within the study area
was logged during a field campaign. Associated with the positional data, the
tree species as well as the DBH was gathered. As stated before, here we only focused
on the determination of the impact of changing resolutions and multi-temporal
predictor variables on the classification accuracy. Therefore, we simplified the
delineation of tree crowns corresponding to the needs of the investigation. First,
we excluded all trees with a DBH below 40 cm, because we assumed that the crowns
of greater trees would cover the smaller ones and thus they could not be observed
on aerial images from above the crown cover. Secondly, we buffered the central 
positions of the residual trees by a square of 2 x 2 m, assuming that with this
size we would essentially cover substantial proportions of the associated tree 
crown (**Fig. 1**). However, some of these buffered polygons intersected. 
In these cases, we decided to exclude both intersecting polygons since any 
decision to keep one over the other would be arbitrary.In the end, we obtained 
`r nrow(trees@data)` tree individuals of which `r length(which(trees$specID == "BUR"))` 
(`r round(length(which(trees$specID == "BUR")) / nrow(trees@data) * 100)`%)  were _fagus sylvatica_ 
and `r length(which(trees$specID == "EIT"))` 
(`r round(length(which(trees$specID == "EIT")) / nrow(trees@data) * 100)`%) were _quercus robur_.

## RGB indices

We calculated a number of seven color vegetation indices (VI) which can be found in Table 2. 
These color indices were suspected to bare information content on the phenological 
development of tree species during a year. Indices are frequently used in remote sensing
studies due to their relational nature which compensates for influences of illumination and viewing 
geometry on the measured reflectance values of the RGB channels.
They were calculated for each UAV overpass resulting in (7 VIs + RGB) x 6 observations = 60 mono-temporal predictor
variables. Additionally, we calculated the maximum (MAX), minimum (MIN), sum (SUM), standard
deviation (SD), amplitude (AMP) as well as the 25%- (Q25) and 75%-percentile (Q75) values
for each VI and the raw channels resulting in additional 70 seasonal predictors. 

```{r indices, echo=F, message=F, warning=F}
indicesdf = data.frame(name = c("Triangular greenness index",
                                "Green Leaf Index",
                                "Color Index of Vegetation",
                                "Iron Oxide Index",
                                "Visible Vegetation Index",
                                "Green Chromatic Coordinate",
                                "Red Chromatic Coordinate"),
                       abbreviation = c("TGI", 
                                        "GLI", 
                                        "CIVE", 
                                        "IO", 
                                        "VVI", 
                                        "GCC",
                                        "RCC"),
                       formula = c("-0.5 * (190*(R-G) - 120*(R-B))",
                                   "(2*G-R-B) / (2*G+R+B)",
                                   "(0.441*R-0.881*G + 0.385*B + 18.787)",
                                   "R/B",
                                   "(1-|R-30| / |R+30|) * \n
                                 (1- |G-50| / |G+50|) * \n 
                                 (1-|B-1| / |B+1|)",
                                 "G / (R+G+B)",
                                 "R / (R+G+B)"),
                       reference = c("Broge and Leblanc (2001)",
                                     "Gobron et al. (2000)",
                                     "Wan et al. (2018)",
                                     "Rowan and Mars (2003)",
                                     "Planetary Habitability Laboratory (2015)",
                                     "Sonnentag et al. (2012)",
                                     "Richardson et al. (2009)"))

kable(indicesdf, format = "latex", linesep="", align = "l", booktabs = T,
      caption = "Names and formulas of calculated RGB indices.") %>%
  kable_styling(latex_options = c("scale_down","HOLD_position")) %>%
  row_spec(0,bold=TRUE) %>%
  footnote(general = "R: 580-670 nm, G: 480-610 nm, B: 400-520 nm, for digital cameras according to Hunt et al. (2012).")
```

Fig. 2 shows the trajectory of the calculated VIs according to the tree species
indicating the mean value (solid line) as well as one standard deviation from the mean
(dashed lines) based on all pixels within tree polygons. The trajectories are very
similar for both classes, however, for almost all VIs there are substantial differences
between the classes during the first observations during the month of May.  

```{r predictor_plots_indices, echo=F, message=F, warning=F, fig.cap="Temporal dynamic of calculated VIs over the course of the year by tree species at 25 cm resolution (dashed lines represent +/- one standard deviation)."}

if (!file.exists("ind_data.rds")){
  indices_names = readRDS("../../data/indices/names_indices_stack.rds")
  indices = raster::stack(list.files("../../data/indices", pattern="25", full.names=TRUE))
  names(indices) = indices_names
  fagus =  rasterize(trees[trees$specID == "BUR",], rgb, 1)
  quercus =  rasterize(trees[trees$specID == "EIT",], rgb, 1)
}


if (!file.exists("ind_data.rds")){
  ind_fagus = as_tibble(indices[fagus])
  ind_fagus$species = "fagus"
  
  ind_quercus = as_tibble(indices[quercus])
  ind_quercus$species = "quercus"
  ind = bind_rows(ind_fagus, ind_quercus)
  substr(names(ind)[1:42], 12, 12) = "-"
  
  ind = ind %>%
    gather(key, value, -species) %>%
    separate(key, c("date", "index"), "-") %>%
    mutate(date = as.Date(date, format = "X%Y_%m_%d"))
  saveRDS(ind, "ind_data.rds")
} else {
  ind = readRDS("ind_data.rds")
}

max_sd = function(x) { mean(x) + sd(x)}
min_sd = function(x) { mean(x) - sd(x)}

ggplot(ind, aes(x=date, y=value, col=species)) +
  stat_summary(fun.y = "mean", geom = "line") +
  stat_summary(fun.y = max_sd, geom = "line", lty = "dashed")+
  stat_summary(fun.y = min_sd, geom = "line", lty = "dashed")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  facet_wrap(. ~ index, scales = "free")

```

Concerning the frequency of the seasonal predictor variables both tree species
are characterized by a very similar distribution (Fig. 3).  



```{r example_seasonal_plots, echo=F, warning=F, message=F, fig.cap="Exampalary histogramm plot of seasonal parameters for RCC by tree species at 25 cm resolution (counts are in pixel) ."}

if (!file.exists("ses_data.rds")){
  seasonal_names = readRDS("../../data/season/season_names.rds")
  seasons = raster::stack(list.files("../../data/season", pattern="25", full.names=TRUE))
  names(seasons) = seasonal_names
  fagus =  rasterize(trees[trees$specID == "BUR",], rgb, 1)
  quercus =  rasterize(trees[trees$specID == "EIT",], rgb, 1)
}

if (!file.exists("ses_data.rds")){
  ses_fagus = as_tibble(seasons[fagus])
  ses_fagus$species = "fagus"
  ses_quercus = as_tibble(seasons[quercus])
  ses_quercus$species = "quercus"
  ses = bind_rows(ses_fagus, ses_quercus)
  paras = c("MAX", "MIN", "AMP", "SD", "SUM", "Q25", "Q75")
  for (i in paras){ names(ses) = str_replace(names(ses),i, paste("-", i, sep =  ""))}
  names(ses) = str_remove(names(ses), "season_")
  ses = ses %>%
    gather(key, value, -species) %>%
    separate(key, c("index", "parameter"), "-")
  saveRDS(ses, "ses_data.rds")
} else {
  ses = readRDS("ses_data.rds")
}

ggplot(filter(ses, index == "GCC"), aes(value, fill=species)) +
  facet_wrap(. ~ parameter, scales = "free")+
  geom_histogram()+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Classification and Validation

For the classification of tree species we used a Random Forest model based
on a forward-feature selection of predictor variables stratified by a leave-location-out
five-fold cross-validation technique. Random Forest is a non-parametric model, both suitable
for regression and classification problems. It was developed by @Breimann2001 and 
is works by the establishment of a number of decision trees, the forest, each 
constructed on a random split of predictor variables. The final class decision is
made by a majority vote of all trees in the forest. We used the implementation
in the `caret` package [@R-caret]. 

# Results

To validate the models, the Kappa value is first determined. If the raters agree in all their judgments, the kappa value is equal to 1, and if there are only matches between the two raters that mathematically correspond to the extent of the randomness, it assumes a value of zero @Greve1997. Kappa values between 0.6 and 0.4 are still considered acceptable, values below 0.40 should be regarded with skepticism. Interrater reliability values of 0.75 are considered good to excellent @Greve1997.

Figure 4 shows that all models excluding the model with a resolution of 25cm and all variables used, regardless of the use of seasonal and vegetation indices and resolution, have a kappa value significantly below the acceptable limit of 0.4. The Kappa value for mono-temporal and seasonal indices increases with decreasing resolution. The comparison shows that the models calculated exclusively with mono-temporal indices show a significantly higher Kappa value than the models calculated exclusively with seasonal indices. Overall, it can be seen that the models with a lowest resolution of 25 cm achieve significantly better Kappa values than the models with a high resolution of 10 cm.


```{r result_plots,  warning=F, message=F, fig.cap="Kappa scores of the random forest models based on varying pixel sizes and predictor variables (green - mono-temporal indices, blue - seasonal indices, red - mono-temporal and seasonal indices).", out.width="60%"}

models = list.files("../results", pattern = "\\.rds$", full.names = T)

getModelMetric <- function(model, metric){
  decomp = str_split(str_split(model, "/")[[1]][3], "_")[[1]]
  if (length(decomp) == 2){
    res = str_sub(decomp[2],4,5)
    type = "all"
  } else {
    res =  str_sub(decomp[3],4,5)
    type = decomp[2]
  }
  
  model = readRDS(model)
  besthyper = as.numeric(model$bestTune)
  if (!metric %in% c("Kappa", "Accuracy")) stop("chosen metric not valid.")
  if (metric == "Kappa"){
    metricVal = model$results$Kappa[which(model$results$mtry == besthyper)]}
  if (metric == "Accuracy"){
    metricVal = model$results$Accuracy[which(model$results$mtry == besthyper)]}
  df_return = data.frame(resolution=res, type=type, metric=metricVal)
  names(df_return)[3] = metric
  return(df_return)
}

kappas = do.call("rbind", lapply(models, getModelMetric, metric="Kappa"))
kappas$type = factor(kappas$type, levels(kappas$type)[c(2,1,3)])

ggplot(data = kappas, aes(x=resolution)) +
  geom_point(aes(y=Kappa, shape=type, col=type), size=2)+
  theme_minimal()


#accuracies = do.call("rbind", lapply(models, getModelMetric, metric="Accuracy"))

# ggplot(data = accuracies, aes(x=resolution)) +
#   geom_point(aes(y=Accuracy, shape=type, col=type), size=2)+
#   theme_minimal()

```

As a further statistical measure of quality, the accuracy of species classification on an object basis is investigated. An object is considered correctly classified if a majority of the pixels belonging to the object type exist. Figure 6 shows the percentage of objects classified as correct species based on the pixels classified in it. It is clearly shown that, regardless of the variables used, the accuracy of object classification increases from a resolution of 10 cm to a resolution of 15 cm. The next worse resolution, on contrast, has a negative effect respectively for the model with all used variables a stagnating effect regarding the object classification. It is striking that the models where mono-temporal and seasonal indices were used in combination had the lowest accuracy in object classification but the highest kappa values compared to Figure 5.

```{r validation_plots, warning=F, message=F, fig.cap="Overall Accuracy (OA) of species classification for tree object classification based on varying pixel sizes and predictor variables (green - mono-temporal indices, blue - seasonal indices, red - mono-temporal and seasonal indices). Note that for the 25cm resolution the OA for mono-temporal indices and all predictor variables is equally at 0.89.", out.width="60%"}
predictions = readRDS("../../results/validation_pred.rds")
index = predictions$index

metrics = predictions %>%
  select(-index) %>%
  map(function(x) factor(x, levels=1:2, labels=c("BUR", "EIT"))) %>%
  map(function(x) caret::confusionMatrix(trees$specID[index], x)) %>%
  map(function(x) tibble(accuracy = x$overall[1], kappa = x$overall[2] ))

results = do.call("rbind", metrics)
resolutions = stringr::str_sub(names(predictions)[-10],-2,-1)

types = stringr::str_sub(names(predictions)[-10],5, 7)
types[types=="IND"] = "indices"
types[types=="SES"] = "seasons"
types[types=="ALL"] = "all"
results$resolution = factor(resolutions)
results$type = factor(types) 


ggplot(data = results, aes(x=resolution)) +
  geom_point(aes(y=kappa, shape=type, col=type), size=2) +
  ggplot2::labs(y = "accuracy") +
  theme_minimal()

```


The variable importance describes the explanatory part a variable has in the model in percent. Figures 7, 8 and 9 show predictor and explanatory parts of the model for the models with mono-temporal indices, seasonal indices and both in combination. The explanation percentages of the individual predictors were calculated from the respective models. The variable with the highest explanatory share is shown as 100%.  The explanation share of the remaining variables is shown in relation to the variable with the highest explanation share.

For models with mono-temporal predictors, the GCC, GLI and VVI indices are of particular importance (Fig. 7). It is noticeable that the aerial photographs of June 5th play an important role in the model calculation. When seasonal predictors are used for model calculation, Figure 8 shows that the RCC index is of great importance (Fig.8). A significant statistical measure of model explanation is not apparent.

Looking at the explanatory share for models calculated using a combination of mono-temporal and seasonal indices, it is noticeable that significantly more mono-temporal predictors are important than seasonal predictors. Furthermore, it can be seen that the significance of mono-temporal predictors for model explanation changes (Fig.9). Thus, it is shown that the GCC index of April 29th is of higher importance than the models for which only mono-temporal predictors were used. In addition, completely different predictors, irrespective of whether they are mono-temporal or seasonal, have an influence on the model explanation than in the models shown above with exclusively mono-temporal or seasonal predictors. It is also striking that June 5 is still of great importance for the model explanation. The situation is similar for the GCC, RCC, VVI and GLI indices.

```{r var_imp_indices, echo=F, warning=F, message=F, fig.cap="Scaled relative variable importance for models with mono-temporal predictors and across all resolutions."}
getVarImp <- function(model){
  decomp = str_split(str_split(model, "/")[[1]][3], "_")[[1]]
  if (length(decomp) == 2){
    res = str_sub(decomp[2],4,5)
    type = "all"
  } else {
    res =  str_sub(decomp[3],4,5)
    type = decomp[2]
  }
  
  model = readRDS(model)
  tmp = importance(model$finalModel)[,3]
  vars = names(tmp)
  
  indexR = which(str_detect(vars, "res5.1"))
  indexG = which(str_detect(vars, "res5.2"))
  indexB = which(str_detect(vars, "res5.3"))
  if( length(indexR) > 0) vars[indexR] = str_replace(vars[indexR], "res5.1", "R")
  if( length(indexG) > 0) vars[indexG] = str_replace(vars[indexG], "res5.2", "G")
  if( length(indexB) > 0) vars[indexB] =str_replace(vars[indexB], "res5.3", "B")
  
  results_df = data.frame(variable=vars, varImp=tmp, resolution=res, type=type)
  rownames(results_df) = NULL
  return(results_df)
}

metric = lapply(models, getVarImp)
metrics = as_tibble(do.call("rbind", metric))
paras = c("MAX", "MIN", "AMP", "SD", "SUM", "Q25", "Q75")
for (i in paras){ metrics$variable = str_replace(metrics$variable,i, paste("-", i, sep =  ""))}
for (i in as.character(metrics$abbreviation)) {metrics$variable = str_replace(metrics$variable, paste0("_",i), paste("-", i, sep =  ""))}
metrics$variable = str_replace(metrics$variable, "X2","2")
metrics$variable = str_remove(metrics$variable, "season-")
metrics$variable = str_replace_all(metrics$variable ,"_","/")
metrics$variable = factor(metrics$variable)

varImpInd = filter(metrics, type == "indices")
varImpInd$variable = droplevels(varImpInd$variable)
varImpInd$variable = reorder(varImpInd$variable, varImpInd$varImp)

varImpSes = filter(metrics, type == "season")
varImpSes$variable = droplevels(varImpSes$variable)
varImpSes$variable = reorder(varImpSes$variable, varImpSes$varImp)

varImpAll = filter(metrics, type == "all")
varImpAll$variable = droplevels(varImpAll$variable)
varImpAll$variable = reorder(varImpAll$variable, varImpAll$varImp)



varImpInd %>%
  group_by(variable) %>%
  summarise(value = sum(varImp, n = n())) %>%
  ungroup() %>%
  mutate(variable = fct_reorder(variable, value)) %>%
  mutate(value = value / max(value) * 100) %>%
  ggplot(aes(x=variable, y=value))+
  geom_bar(stat="identity", fill = "dodgerblue1")+
  theme_minimal()+
  coord_flip()
```

```{r var_imp_season, echo=F, warning=F, message=F, fig.cap="Scaled relative variable importance for models with seasonal predictors and across all resolutions."}

varImpSes %>%
  group_by(variable) %>%
  summarise(value = sum(varImp, n = n())) %>%
  ungroup() %>%
  mutate(variable = fct_reorder(variable, value)) %>%
  mutate(value = value / max(value) * 100) %>%
  ggplot(aes(x=variable, y=value))+
  geom_bar(stat="identity", fill = "dodgerblue1")+
  theme_minimal()+
  coord_flip()
```

```{r var_imp_all, echo=F, warning=F, message=F, fig.cap="Scaled relative variable importance for models with all predictors variables and across all resolutions."}


varImpAll %>%
  group_by(variable) %>%
  summarise(value = sum(varImp, n = n())) %>%
  ungroup() %>%
  mutate(variable = fct_reorder(variable, value)) %>%
  mutate(value = value / max(value) * 100) %>%
  ggplot(aes(x=variable, y=value))+
  geom_bar(stat="identity", fill = "dodgerblue1")+
  theme_minimal()+
  coord_flip()
```


```{r var_imp_together, echo=F, warning=F, message=F, fig.cap="Scaled relative variable importance across all models and accross all resolutions."}


metrics %>%
  group_by(variable) %>%
  summarise(value = sum(varImp, n = n())) %>%
  ungroup() %>%
  mutate(variable = fct_reorder(variable, value)) %>%
  mutate(value = value / max(value) * 100) %>%
  ggplot(aes(x=variable, y=value))+
  geom_bar(stat="identity", fill = "dodgerblue1")+
  theme_minimal()+
  coord_flip()
```

# Discussion

Due to several sources of error the obtained results do not allow a consistent interpretation on the effects of resolution and the selection of predictor variables. As mentioned above and shown in **figure 2** the pre-processing and georeferencing of the drone images introduced distortion artifacts which lead to false pixel readouts at the sampling trees locations. Further the representation of trees in our training data as described in **2.3**, in combination with the described image distortion is a massive source of error, that can't be ignored.
--> im Endeffekt sagt der Kappa ja, dass kein Modell annehmbar ist. 
--> Vielleicht nochmal erw?hnen, dass das die grundlage war und nicht unser verschulden?

The models results, measured by the kappa score indicate a stronger, but not much stronger ability than random chance to predict tree species at our study site. Although the results do not appear to be too promising for an overall tree species classification they are very well capable of highlighting key differences resulting from changed methodologies during the model training process. Models trained with both mono-temporal and seasonal indices performed best overall closely followed by models trained with mono-temporal indices only. Thus leading us to the conclusion, that mono-temporal predictors are more important than seasonal predictors but a combination of both improve model performance slightly. Comparing those results with object based validation accuracy scores seen in **figure 6** a big discrepancy is noticeable. A possible explanation may be the over representation of fagus sylvatica pixels when predicting tree species on all available tree objects. A contributing factor to that over representation may be the decreasing resolution, as more "fagus sylvatica" pixels are crunched into bigger sized pixels and thus smoothing out the already underrepresented quercus robur pixels. 

--> Vielleicht erwhnen, dass saisonale indices besser sein k?nnten, nur f?r den geeigneten zeitraum evtl kein Bild vorhanden war, beispielsweise irgendein saisonales merkmal wegen der zeit verpasst wurde. ich denke da an abbildung 3 in unserem bericht?
--> vielelicht noch auf die indices eingehen warum gerade diese ausgew?hlt wurden?
https://www.researchgate.net/figure/Vegetation-canopy-greenness-as-quantified-by-green-chromatic-coordinate-GCC-using_fig1_296618875 sowas vielleicht?
https://www.researchgate.net/figure/Daily-green-red-and-blue-chromatic-coordinates-GCC-RCC-BCC-and-excess-indices_fig4_312257742
hatte da irgendwas einfluss auf die auswahl der indice irgendein faktor?
also warum wurden gerade RCC GCC GLI UND VVI ausgew?hlt? kenne da gerade keine Begr?ndung. gibts da eine=
-->  WIe siehts damit aus, dass die indices eigentlich f?r satelliten und luftbilder entwickelt wurden. hat das einen einfluss auf drohnenbilde und daher auf die auswahl. also werden bestimmte indices aufgrund des anders einfallenden lichts bevorzugt? und deshalb ausgew?hlt?
--> gibts nen bezug den man zur einleitung ziehen kann?
--> WIr haben mehr buchen im untersuchung und traininsgebiet f?hrt das dazu, dass buchen besser vorhergesagt werden und daher die Modellg?te k?nstlich erh?ht wird?

In order to conduct further analysis on that topic it is strongly recommended to improve the image pre processing steps involved in this study.

# Conclusion
Overall the models performances, described by the kappa score showed a better than random ability to predict tree species at our study area 

# References


